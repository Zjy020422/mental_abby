# ====== DeepSeek API ÈÖçÁΩÆ ======
# ‰ºòÂÖà‰ªéÁéØÂ¢ÉÂèòÈáèËØªÂèñ API ÂØÜÈí•ÔºåÂ¶ÇÊûúÊ≤°ÊúâÂàô‰ΩøÁî®ÈªòËÆ§ÂÄº
import os

DEEPSEEK_API_KEY = os.environ.get('DEEPSEEK_API_KEY', "sk-cb387c428d9343328cea734e6ae0f9f5")

# ====== ÂØºÂÖ•‰æùËµñ ======
# Please install OpenAI SDK first: `pip3 install openai`
from openai import OpenAI
import json
import sqlite3
from datetime import datetime
from typing import Dict, List, Optional
from dataclasses import dataclass
import uuid
import time
from database import DatabaseManager
from analyse import MDQAnalyzer

@dataclass
class AdvisorReport:
    """AIÈ°æÈóÆÊä•ÂëäÊï∞ÊçÆÁ±ª"""
    report_id: str
    user_id: str
    report_type: str  # 'single_test' Êàñ 'historical_analysis'
    analysis_id: Optional[str]  # ÂçïÊ¨°ÂàÜÊûêIDÔºàÂçïÊµãËØïÊä•ÂëäÔºâ
    generated_at: datetime
    
    # AIÁîüÊàêÁöÑÊä•ÂëäÂÜÖÂÆπ
    executive_summary: str
    clinical_assessment: Optional[str] = None
    risk_evaluation: Optional[str] = None
    treatment_recommendations: Optional[str] = None
    lifestyle_recommendations: Optional[str] = None
    monitoring_plan: Optional[str] = None
    emergency_protocols: Optional[str] = None
    
    # Âü∫‰∫éÂéÜÂè≤ÁöÑÂÜÖÂÆπÔºàÂéÜÂè≤ÂàÜÊûêÊä•ÂëäÔºâ
    progress_analysis: Optional[str] = None
    trend_interpretation: Optional[str] = None
    prognosis_assessment: Optional[str] = None
    
    # ÂÖÉÊï∞ÊçÆ
    confidence_score: float = 0.0
    ai_model_version: str = "deepseek-chat"
    processing_time: float = 0.0

class DeepSeekAdvisor:
    """DeepSeek AI ÂàÜÊûêÈ°æÈóÆ"""
    
    def __init__(self, db_manager: DatabaseManager, analyzer: MDQAnalyzer):
        self.db_manager = db_manager
        self.analyzer = analyzer
        self.client = None
        self.api_available = False

        # Validate API key and initialize client
        try:
            if not DEEPSEEK_API_KEY or DEEPSEEK_API_KEY == "your_deepseek_api_key_here":
                print("WARNING: DeepSeek API key not set, using fallback report generation mode")
                self.api_available = False
            else:
                # Initialize OpenAI client
                self.client = OpenAI(
                    api_key=DEEPSEEK_API_KEY,
                    base_url="https://api.deepseek.com"
                )
                self.api_available = True
                print("SUCCESS: DeepSeek API client initialized")
        except Exception as e:
            print(f"WARNING: DeepSeek API initialization failed: {e}")
            print("WARNING: Using fallback report generation mode")
            self.api_available = False

        self._init_database_tables()
        
        # AI Prompt Templates
        self.prompts = {
            'single_test': {
                'system': """You are an experienced psychiatrist and bipolar disorder specialist. Based on the patient's MDQ questionnaire analysis results, generate a professional clinical assessment report and treatment recommendations.

IMPORTANT: Please respond in English only. All content must be in English.

Please provide analysis in the following 7 sections with a professional, objective, and caring tone (strictly follow this format):

[EXECUTIVE SUMMARY]: Briefly summarize the patient's current status (2-3 sentences)
[CLINICAL ASSESSMENT]: Detailed analysis of symptom presentation and severity
[RISK EVALUATION]: Assessment of current risks and potential dangers
[TREATMENT RECOMMENDATIONS]: Specific medical intervention recommendations (each recommendation on a separate line, starting with "-")
[LIFESTYLE RECOMMENDATIONS]: Daily management and self-care (each recommendation on a separate line, starting with "-")
[MONITORING PLAN]: Follow-up tracking and assessment plan
[EMERGENCY PROTOCOLS]: Crisis management procedures

Ensure all recommendations are evidence-based and follow clinical practice guidelines. All output must be in English.""",

                'user_template': """Please generate an MDQ analysis report for the following patient:

**Patient Demographics:**
- Age: {age} years
- Gender: {gender}
- Total Assessments: {total_assessments}
- Assessment Time Span: {assessment_span_days} days

**Current Clinical Status:**
- MDQ Score: {mdq_score}/13
- Weighted Score: {weighted_score}
- Severity Level: {severity_level}
- Risk Percentage: {risk_percentage}%
- Functional Impairment: {functional_impairment}

**Symptom Distribution:**
{symptom_distribution}

**Bipolar Risk Profile:**
{bipolar_risk_profile}

**Positive Symptoms:**
{positive_symptoms}

**Emergency Indicators:** {emergency_indicators}

**Monitoring Priorities:** {monitoring_priorities}

**Intervention Targets:** {intervention_targets}

Please generate a complete clinical assessment report and treatment recommendations."""
            },
            
            'historical': {
                'system': """You are a psychiatrist specializing in long-term treatment and management of bipolar disorder. Based on the patient's historical MDQ assessment data, analyze treatment progress and prognosis, and provide comprehensive long-term treatment recommendations.

IMPORTANT: Please respond in English only. All content must be in English.

Please provide analysis in the following 5 sections (strictly follow this format):

[EXECUTIVE SUMMARY]: Brief overview of overall treatment progress and current status (2-3 sentences)
[PROGRESS ANALYSIS]: Analysis of treatment effectiveness and symptom trajectory, including improvement trends and consistency assessment
[TREND INTERPRETATION]: Professional interpretation and prediction of symptom trends based on historical data patterns
[TREATMENT RECOMMENDATIONS]: Specific medical interventions and lifestyle recommendations based on historical analysis (each recommendation on a separate line, starting with "-")
[PROGNOSIS ASSESSMENT]: Long-term prognosis and recovery potential assessment, including risk factors and protective factors

Provide recommendations based on evidence-based medicine and long-term management best practices. All output must be in English.""",

                'user_template': """Please generate a historical trend analysis report for the following patient:

**Patient Demographics:**
- Age: {age} years
- Gender: {gender}
- Total Assessments: {total_assessments}
- Time Span: {assessment_span_days} days

**Current Status:**
- Current MDQ Score: {current_score}/13
- Severity Level: {severity_level}
- Risk Percentage: {risk_percentage}%

**Historical Trajectory:**
- Improvement Trend: {improvement_trend}
- Trend Confidence: {trend_confidence}
- Historical Baseline: {baseline_score}
- Improvement Percentage: {improvement_percentage}%
- Consistency Score: {consistency_score}

**Score Timeline:**
{score_timeline}

**Treatment Response Indicators:**
{treatment_indicators}

**Recovery Indicators:**
{recovery_indicators}

**Current Risk Factors:**
{current_risk_factors}

**Prognostic Factors:**
- Positive Factors: {positive_factors}
- Negative Factors: {negative_factors}

**Statistical Features:**
- Mean Score: {score_mean}
- Standard Deviation: {score_std}
- Score Range: {score_range}
- Variability Coefficient: {variability_coefficient}

Based on this historical data, please generate a comprehensive progress assessment report and long-term treatment recommendations in english."""
            }
        }
    
    def _init_database_tables(self):
        """ÂàùÂßãÂåñAIÈ°æÈóÆÊä•ÂëäÊï∞ÊçÆÂ∫ìË°®"""
        try:
            conn = self.db_manager._get_connection()
            cursor = conn.cursor()
            
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS ai_advisor_reports (
                    report_id TEXT PRIMARY KEY,
                    user_id TEXT NOT NULL,
                    report_type TEXT NOT NULL CHECK(report_type IN ('single_test', 'historical_analysis')),
                    analysis_id TEXT,
                    generated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    
                    -- AIÁîüÊàêÁöÑÂÜÖÂÆπ
                    executive_summary TEXT NOT NULL,
                    clinical_assessment TEXT NOT NULL,
                    risk_evaluation TEXT NOT NULL,
                    treatment_recommendations TEXT NOT NULL,
                    lifestyle_recommendations TEXT NOT NULL,
                    monitoring_plan TEXT NOT NULL,
                    emergency_protocols TEXT NOT NULL,
                    
                    -- ÂéÜÂè≤ÂàÜÊûêÁâπÊúâÂÜÖÂÆπ
                    progress_analysis TEXT,
                    trend_interpretation TEXT,
                    prognosis_assessment TEXT,
                    
                    -- ÂÖÉÊï∞ÊçÆ
                    confidence_score REAL DEFAULT 0.0,
                    ai_model_version TEXT DEFAULT 'deepseek-chat',
                    processing_time REAL DEFAULT 0.0,
                    
                    -- ÂéüÂßãÊï∞ÊçÆ
                    ai_input_data TEXT,
                    ai_response_raw TEXT,
                    
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    
                    FOREIGN KEY (user_id) REFERENCES users (user_id) ON DELETE CASCADE,
                    FOREIGN KEY (analysis_id) REFERENCES mdq_analysis_results (analysis_id) ON DELETE SET NULL
                )
            ''')
            
            # ÂàõÂª∫Á¥¢Âºï
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_advisor_user_type ON ai_advisor_reports(user_id, report_type)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_advisor_generated_at ON ai_advisor_reports(generated_at)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_advisor_analysis_id ON ai_advisor_reports(analysis_id)')
            
            conn.commit()
            print("AIÈ°æÈóÆÊä•ÂëäÊï∞ÊçÆÂ∫ìË°®ÂàùÂßãÂåñÂÆåÊàê")
            
        except sqlite3.Error as e:
            print(f"AIÈ°æÈóÆÊï∞ÊçÆÂ∫ìË°®ÂàùÂßãÂåñÂ§±Ë¥•: {e}")
        finally:
            if conn:
                conn.close()
    
    def generate_single_test_report(self, analysis_id: str) -> AdvisorReport:
        """ÁîüÊàêÂçïÊ¨°ÊµãËØïÂàÜÊûêÊä•Âëä - ‰øÆÂ§çÁâà"""
        start_time = time.time()
        
        try:
            # Ëé∑ÂèñÂàÜÊûêÊï∞ÊçÆ
            analysis_detail = self.analyzer.get_analysis_detail(analysis_id)
            if not analysis_detail:
                raise ValueError(f"ÂàÜÊûêËÆ∞ÂΩï {analysis_id} ‰∏çÂ≠òÂú®")
            
            ai_data = self.analyzer.get_ai_analysis_data(analysis_id)
            if not ai_data:
                # Â¶ÇÊûúÊ≤°ÊúâAIÊï∞ÊçÆÔºåÂ∞ùËØï‰ªéanalysis_detailÊûÑÈÄ†
                print(f"Ë≠¶ÂëäÔºöÊ≤°ÊúâÊâæÂà∞AIÂàÜÊûêÊï∞ÊçÆÔºåÂ∞ùËØï‰ªéÂàÜÊûêËØ¶ÊÉÖÊûÑÈÄ†Âü∫Á°ÄÊï∞ÊçÆ")
                ai_data = {
                    'mdq_part1_score': analysis_detail.get('mdq_part1_score', 0),
                    'has_co_occurrence': analysis_detail.get('has_co_occurrence', False),
                    'functional_impact_level': analysis_detail.get('functional_impact_level', 'no_problems'),
                    'mdq_result': analysis_detail.get('mdq_result', 'negative'),
                    'severity_level': analysis_detail.get('severity_level', 'negative'),
                    'risk_percentage': analysis_detail.get('risk_percentage', 0),
                    'positive_symptoms': json.loads(analysis_detail.get('positive_symptoms', '[]')) if analysis_detail.get('positive_symptoms') else [],
                    'core_symptoms_count': analysis_detail.get('core_symptoms_count', 0)
                }
            
            user_id = analysis_detail['user_id']
            
            # ÂáÜÂ§áAIËæìÂÖ•Êï∞ÊçÆ
            ai_input = self._prepare_single_test_input(ai_data)
            print(f"AIËæìÂÖ•Êï∞ÊçÆÂáÜÂ§áÂÆåÊàê: MDQÂàÜÊï∞={ai_input['mdq_score']}, È£éÈô©={ai_input['risk_percentage']}%")
            
            # Ë∞ÉÁî®DeepSeek API
            user_prompt = self.prompts['single_test']['user_template'].format(**ai_input)
            
            try:
                ai_response = self._call_deepseek_api(
                    self.prompts['single_test']['system'],
                    user_prompt
                )
                print(f"DeepSeek APIË∞ÉÁî®ÊàêÂäüÔºåÂìçÂ∫îÈïøÂ∫¶: {len(ai_response)}")
            except Exception as api_error:
                print(f"DeepSeek APIË∞ÉÁî®Â§±Ë¥•: {api_error}")
                # ÁîüÊàêÂ§áÁî®Êä•Âëä
                ai_response = self._generate_fallback_report(ai_input)
            
            # Ëß£ÊûêAIÂìçÂ∫î
            parsed_response = self._parse_single_test_response(ai_response)
            
            # ËÆ°ÁÆóÂ§ÑÁêÜÊó∂Èó¥
            processing_time = time.time() - start_time
            
            # ÂàõÂª∫Êä•ÂëäÂØπË±°
            report = AdvisorReport(
                report_id=str(uuid.uuid4()),
                user_id=user_id,
                report_type='single_test',
                analysis_id=analysis_id,
                generated_at=datetime.now(),
                
                executive_summary=parsed_response['executive_summary'],
                clinical_assessment=parsed_response['clinical_assessment'],
                risk_evaluation=parsed_response['risk_evaluation'],
                treatment_recommendations=parsed_response['treatment_recommendations'],
                lifestyle_recommendations=parsed_response['lifestyle_recommendations'],
                monitoring_plan=parsed_response['monitoring_plan'],
                emergency_protocols=parsed_response['emergency_protocols'],
                
                confidence_score=parsed_response.get('confidence_score', 0.8),
                processing_time=processing_time
            )
            
            # ‰øùÂ≠òÂà∞Êï∞ÊçÆÂ∫ì
            self._save_report(report, ai_input, ai_response)
            
            return report
            
        except Exception as e:
            print(f"ÁîüÊàêÂçïÊ¨°ÊµãËØïÊä•ÂëäÂ§±Ë¥•: {e}")
            import traceback
            traceback.print_exc()
            raise e
    def _generate_fallback_report(self, ai_input: Dict) -> str:
        """Generate fallback report (when API call fails)"""
        mdq_score = ai_input.get('mdq_score', 0)
        risk_percentage = ai_input.get('risk_percentage', 0)

        if mdq_score >= 7:
            severity = "requires attention"
            recommendations = [
                "Consult with a mental health professional as soon as possible",
                "Monitor mood and behavioral changes closely",
                "Maintain regular sleep schedule"
            ]
            lifestyle = [
                "Avoid excessive stress and overstimulation",
                "Engage in moderate exercise",
                "Seek support from family and friends"
            ]
        else:
            severity = "relatively stable"
            recommendations = [
                "Continue monitoring mental health status",
                "Seek medical attention if symptoms change"
            ]
            lifestyle = [
                "Maintain healthy lifestyle habits",
                "Schedule regular mental health assessments"
            ]

        return f"""
    [EXECUTIVE SUMMARY]: Based on MDQ assessment results ({mdq_score}/13 points), the patient's current status is {severity}. Continued monitoring and professional evaluation are recommended.

    [CLINICAL ASSESSMENT]: The MDQ questionnaire shows a patient score of {mdq_score} points, with a risk assessment of {risk_percentage}%. According to standard MDQ scoring criteria, {'further professional evaluation is recommended' if mdq_score >= 7 else 'no obvious abnormalities, but continued monitoring is needed'}.

    [RISK EVALUATION]: {'Moderate risk - professional medical evaluation needed' if mdq_score >= 7 else 'Low risk - regular follow-up recommended'}.

    [TREATMENT RECOMMENDATIONS]:
    {chr(10).join(f'- {rec}' for rec in recommendations)}

    [LIFESTYLE RECOMMENDATIONS]:
    {chr(10).join(f'- {rec}' for rec in lifestyle)}

    [MONITORING PLAN]: {'Monthly' if mdq_score >= 7 else 'Quarterly'} mental health assessments are recommended. Seek medical attention promptly if symptoms change.

    [EMERGENCY PROTOCOLS]: If severe mood swings, self-harm or suicidal thoughts, or severe functional impairment occur, please contact a medical professional immediately or call emergency services.

    *Note: This report uses fallback generation mode due to network issues. Detailed evaluation by a professional physician is recommended.*
    """
    def generate_historical_analysis_report(self, user_id: str) -> AdvisorReport:
        """ÁîüÊàêÂéÜÂè≤Ë∂ãÂäøÂàÜÊûêÊä•Âëä"""
        start_time = time.time()
        
        # Ëé∑ÂèñÁî®Êà∑ÊúÄÊñ∞ÂàÜÊûê
        analysis_history = self.analyzer.get_analysis_history(user_id, limit=1)
        if not analysis_history:
            raise ValueError(f"Áî®Êà∑ {user_id} Ê≤°ÊúâÂàÜÊûêËÆ∞ÂΩï")
        
        latest_analysis_id = analysis_history[0]['analysis_id']
        ai_data = self.analyzer.get_ai_analysis_data(latest_analysis_id)
        
        if not ai_data:
            raise ValueError(f"Áî®Êà∑ {user_id} ÁöÑAIÊï∞ÊçÆ‰∏çÂÆåÊï¥")
        
        # ÂáÜÂ§áAIËæìÂÖ•Êï∞ÊçÆ
        ai_input = self._prepare_historical_input(ai_data)
        
        # Ë∞ÉÁî®DeepSeek API
        user_prompt = self.prompts['historical']['user_template'].format(**ai_input)
        ai_response = self._call_deepseek_api(
            self.prompts['historical']['system'],
            user_prompt
        )
        
        # Ëß£ÊûêAIÂìçÂ∫î
        parsed_response = self._parse_historical_response(ai_response)
        
        # ËÆ°ÁÆóÂ§ÑÁêÜÊó∂Èó¥
        processing_time = time.time() - start_time
        
        # ÂàõÂª∫Êä•ÂëäÂØπË±°
        report = AdvisorReport(
            report_id=str(uuid.uuid4()),
            user_id=user_id,
            report_type='historical_analysis',
            analysis_id=latest_analysis_id,
            generated_at=datetime.now(),
            
            executive_summary=parsed_response['executive_summary'],
            clinical_assessment=parsed_response.get('clinical_assessment', ''),
            risk_evaluation=parsed_response.get('risk_evaluation', ''),
            treatment_recommendations=parsed_response.get('treatment_recommendations', ''),
            lifestyle_recommendations=parsed_response.get('lifestyle_recommendations', ''),
            monitoring_plan=parsed_response.get('monitoring_plan', ''),
            emergency_protocols=parsed_response.get('emergency_protocols', ''),
            
            progress_analysis=parsed_response['progress_analysis'],
            trend_interpretation=parsed_response['trend_interpretation'],
            prognosis_assessment=parsed_response['prognosis_assessment'],
            
            confidence_score=parsed_response.get('confidence_score', 0.8),
            processing_time=processing_time
        )
        
        # ‰øùÂ≠òÂà∞Êï∞ÊçÆÂ∫ì
        self._save_report(report, ai_input, ai_response)
        
        return report
    
    def _prepare_single_test_input(self, ai_data: Dict) -> Dict:
        """ÂáÜÂ§áÂçïÊ¨°ÊµãËØïÁöÑAIËæìÂÖ•Êï∞ÊçÆ - ‰øÆÂ§çÁâà"""
        try:
            # ‰ªé‰∏çÂêåÁöÑÊï∞ÊçÆÁªìÊûÑ‰∏≠ÊèêÂèñ‰ø°ÊÅØ
            demographics = ai_data.get('patient_demographics', {})
            mdq_standard = ai_data.get('mdq_standard_results', {})
            symptom_patterns = ai_data.get('symptom_patterns', {})
            clinical_context = ai_data.get('clinical_context', {})
            
            # ÂÖºÂÆπÊóßÊï∞ÊçÆÊ†ºÂºè
            if not mdq_standard and 'mdq_part1_score' in ai_data:
                mdq_standard = {
                    'part1_score': ai_data.get('mdq_part1_score', 0),
                    'has_co_occurrence': ai_data.get('has_co_occurrence', False),
                    'functional_impact_level': ai_data.get('functional_impact_level', 'no_problems'),
                    'mdq_result': ai_data.get('mdq_result', 'negative'),
                    'severity_level': ai_data.get('severity_level', 'negative'),
                    'risk_percentage': ai_data.get('risk_percentage', 0)
                }
            
            if not symptom_patterns and 'positive_symptoms' in ai_data:
                symptom_patterns = {
                    'positive_symptoms_list': ai_data.get('positive_symptoms', []),
                    'core_symptoms_count': ai_data.get('core_symptoms_count', 0),
                    'symptom_profile': ai_data.get('symptom_profile', {})
                }
            
            # ÂÆâÂÖ®Ëé∑ÂèñÂü∫Êú¨‰ø°ÊÅØ
            age = demographics.get('age', ai_data.get('age', 'Unknown'))
            gender = demographics.get('gender', ai_data.get('gender', 'Unknown'))
            total_assessments = demographics.get('total_assessments', ai_data.get('total_assessments', 1))
            assessment_span = demographics.get('assessment_span_days', ai_data.get('assessment_span_days', 0))
            
            # ÂÆâÂÖ®Ëé∑ÂèñMDQÁõ∏ÂÖ≥‰ø°ÊÅØ
            mdq_score = mdq_standard.get('part1_score', ai_data.get('mdq_part1_score', 0))
            risk_percentage = mdq_standard.get('risk_percentage', ai_data.get('risk_percentage', 0))
            severity_level = mdq_standard.get('severity_level', ai_data.get('severity_level', 'negative'))
            functional_impact = mdq_standard.get('functional_impact_level', ai_data.get('functional_impact_level', 'no_problems'))
            
            # Â§ÑÁêÜÁóáÁä∂‰ø°ÊÅØ
            positive_symptoms = symptom_patterns.get('positive_symptoms_list', ai_data.get('positive_symptoms', []))
            core_symptoms_count = symptom_patterns.get('core_symptoms_count', ai_data.get('core_symptoms_count', 0))
            
            # Ê†ºÂºèÂåñÁóáÁä∂ÂàÜÂ∏ÉÔºàÁÆÄÂåñÁâàÔºâ
            symptom_categories = symptom_patterns.get('symptom_categories', {})
            if not symptom_categories and 'symptom_profile' in ai_data:
                # ‰ªésymptom_profileÁîüÊàêÁÆÄÂåñÁöÑÂàÜÁ±ª
                profile = ai_data.get('symptom_profile', {})
                mood_symptoms = sum(1 for q in ['q1', 'q2'] if profile.get(q, False))
                cognitive_symptoms = sum(1 for q in ['q5', 'q6'] if profile.get(q, False))
                behavioral_symptoms = sum(1 for q in ['q7', 'q8', 'q9'] if profile.get(q, False))
                
                symptom_categories = {
                    'mood_elevation': {'positive_count': mood_symptoms, 'total_count': 2},
                    'cognitive_symptoms': {'positive_count': cognitive_symptoms, 'total_count': 2},
                    'behavioral_activation': {'positive_count': behavioral_symptoms, 'total_count': 3}
                }
            
            symptom_text = ""
            for category, data in symptom_categories.items():
                if isinstance(data, dict) and 'positive_count' in data:
                    symptom_text += f"- {category.replace('_', ' ').title()}: {data['positive_count']}/{data['total_count']}\n"

            # Format positive symptoms
            symptoms_text = "\n".join([f"- {symptom}" for symptom in positive_symptoms[:5]])  # Limit to first 5
            if not symptoms_text:
                symptoms_text = "No significant positive symptoms"
            
            # Ëé∑Âèñ‰∏¥Â∫ä‰∏ä‰∏ãÊñá
            emergency_indicators = clinical_context.get('emergency_indicators', [])
            monitoring_priorities = clinical_context.get('monitoring_priorities', [])
            intervention_targets = clinical_context.get('intervention_targets', [])
            
            return {
                'age': str(age),
                'gender': str(gender),
                'total_assessments': int(total_assessments),
                'assessment_span_days': int(assessment_span),
                'mdq_score': int(mdq_score),
                'weighted_score': float(mdq_score),  # Simplified: use MDQ score
                'severity_level': str(severity_level).replace('_', ' ').title(),
                'risk_percentage': float(risk_percentage),
                'functional_impairment': str(functional_impact).replace('_', ' ').title(),
                'symptom_distribution': symptom_text if symptom_text else "No detailed symptom distribution data available",
                'bipolar_risk_profile': f"MDQ Positive: {'Yes' if mdq_score >= 7 else 'No'}\nSymptom Co-occurrence: {'Yes' if mdq_standard.get('has_co_occurrence', False) else 'No'}",
                'positive_symptoms': symptoms_text,
                'emergency_indicators': ', '.join(emergency_indicators) if emergency_indicators else 'None',
                'monitoring_priorities': ', '.join(monitoring_priorities) if monitoring_priorities else 'Routine monitoring',
                'intervention_targets': ', '.join(intervention_targets) if intervention_targets else 'No specific intervention targets'
            }
            
        except Exception as e:
            print(f"Failed to prepare AI input data: {e}")
            # Return basic data structure
            return {
                'age': 'Unknown',
                'gender': 'Unknown',
                'total_assessments': 1,
                'assessment_span_days': 0,
                'mdq_score': ai_data.get('mdq_part1_score', 0),
                'weighted_score': ai_data.get('mdq_part1_score', 0),
                'severity_level': 'Requires assessment',
                'risk_percentage': ai_data.get('risk_percentage', 0),
                'functional_impairment': 'Requires assessment',
                'symptom_distribution': 'Error occurred during data processing',
                'bipolar_risk_profile': 'Requires re-assessment',
                'positive_symptoms': 'Failed to retrieve data',
                'emergency_indicators': 'None',
                'monitoring_priorities': 'Professional assessment recommended',
                'intervention_targets': 'Further assessment required'
            }
    
    def _prepare_historical_input(self, ai_data: Dict) -> Dict:
        """ÂáÜÂ§áÂéÜÂè≤ÂàÜÊûêÁöÑAIËæìÂÖ•Êï∞ÊçÆ"""
        demographics = ai_data.get('patient_demographics', {})
        clinical_state = ai_data.get('current_clinical_state', {})
        trajectory = ai_data.get('historical_trajectory', {})
        treatment_response = ai_data.get('treatment_response', {})
        stats = ai_data.get('statistical_features', {})
        prognosis = ai_data.get('clinical_context', {}).get('prognosis_factors', {})
        
        # Format score timeline
        score_timeline = trajectory.get('score_timeline', [])
        timeline_text = "\n".join([
            f"- {point['date'][:10]}: {point['score']} points (Baseline deviation: {point['baseline_deviation']:+.1f})"
            for point in score_timeline[-10:]  # Last 10 records
        ])
        
        # Ê†ºÂºèÂåñÊ≤ªÁñóÊåáÊ†á
        treatment_indicators = treatment_response.get('treatment_indicators', {})
        treatment_text = "\n".join([f"- {k.replace('_', ' ').title()}: {v}" for k, v in treatment_indicators.items() if v != True])
        
        # Ê†ºÂºèÂåñÊÅ¢Â§çÊåáÊ†á
        recovery_indicators = treatment_response.get('recovery_indicators', [])
        recovery_text = "\n".join([f"- {indicator}" for indicator in recovery_indicators])
        
        # Ê†ºÂºèÂåñÈ£éÈô©Âõ†Á¥†
        risk_factors = treatment_response.get('current_risk_factors', [])
        risk_text = "\n".join([f"- {factor}" for factor in risk_factors])
        
        return {
            'age': demographics.get('age', 'Unknown'),
            'gender': demographics.get('gender', 'Unknown'),
            'total_assessments': demographics.get('total_assessments', 0),
            'assessment_span_days': demographics.get('assessment_span_days', 0),
            'current_score': clinical_state.get('mdq_score', 0),
            'severity_level': clinical_state.get('severity_level', 'Unknown'),
            'risk_percentage': clinical_state.get('risk_percentage', 0),
            'improvement_trend': trajectory.get('improvement_trend', 'Unknown'),
            'trend_confidence': round(trajectory.get('trend_confidence', 0), 2),
            'baseline_score': round(trajectory.get('baseline_score', 0), 1),
            'improvement_percentage': round(treatment_response.get('improvement_percentage', 0), 1),
            'consistency_score': round(treatment_response.get('consistency_score', 0), 2),
            'score_timeline': timeline_text if timeline_text else 'Insufficient historical data available',
            'treatment_indicators': treatment_text if treatment_text else 'No treatment response data available',
            'recovery_indicators': recovery_text if recovery_text else 'No significant recovery indicators',
            'current_risk_factors': risk_text if risk_text else 'No significant risk factors',
            'positive_factors': ', '.join(prognosis.get('positive_factors', [])) if prognosis.get('positive_factors') else 'None',
            'negative_factors': ', '.join(prognosis.get('negative_factors', [])) if prognosis.get('negative_factors') else 'None',
            'score_mean': round(stats.get('score_mean', 0), 1),
            'score_std': round(stats.get('score_std', 0), 1),
            'score_range': stats.get('score_range', 0),
            'variability_coefficient': round(stats.get('variability_coefficient', 0), 2)
        }
    
    def _call_deepseek_api(self, system_prompt: str, user_prompt: str) -> str:
        """Call DeepSeek API - Enhanced error handling"""
        # If API unavailable, throw exception for fallback
        if not self.api_available or not self.client:
            raise Exception("DeepSeek API client not initialized or unavailable")

        try:
            # Add timeout and retry mechanism
            import time
            max_retries = 2  # Reduced retries for faster failure response

            for attempt in range(max_retries):
                try:
                    api_start_time = time.time()
                    print(f"[API Call] Attempt {attempt + 1}/{max_retries} - Starting DeepSeek API request...")

                    response = self.client.chat.completions.create(
                        model="deepseek-chat",
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        max_tokens=4000,
                        temperature=0.7,
                        stream=False,
                        timeout=120  # Increased to 120 second timeout for longer responses
                    )

                    api_duration = time.time() - api_start_time
                    response_content = response.choices[0].message.content
                    print(f"[API Call] Success - Duration: {api_duration:.2f}s, Response length: {len(response_content)} chars")

                    return response_content

                except Exception as e:
                    api_duration = time.time() - api_start_time
                    print(f"[API Call] Failed after {api_duration:.2f}s (attempt {attempt + 1}/{max_retries}): {e}")
                    if attempt < max_retries - 1:
                        time.sleep(1)  # Fixed 1 second wait
                    else:
                        raise e

        except Exception as e:
            print(f"[API Call] Ultimately failed: {e}")
            raise Exception(f"DeepSeek API call failed: {str(e)}")
    
    def _parse_single_test_response(self, ai_response: str) -> Dict:
        """Parse single test AI response"""
        sections = {
            'executive_summary': '',
            'clinical_assessment': '',
            'risk_evaluation': '',
            'treatment_recommendations': [],
            'lifestyle_recommendations': [],
            'monitoring_plan': '',
            'emergency_protocols': '',
            'confidence_score': 0.8
        }

        # Split response by sections - support both English and Chinese formats
        section_patterns = {
            '[EXECUTIVE SUMMARY]': 'executive_summary',
            '[CLINICAL ASSESSMENT]': 'clinical_assessment',
            '[RISK EVALUATION]': 'risk_evaluation',
            '[TREATMENT RECOMMENDATIONS]': 'treatment_recommendations',
            '[LIFESTYLE RECOMMENDATIONS]': 'lifestyle_recommendations',
            '[MONITORING PLAN]': 'monitoring_plan',
            '[EMERGENCY PROTOCOLS]': 'emergency_protocols',
            # Fallback to Chinese patterns for compatibility
            '„ÄêÊâßË°åÊëòË¶Å„Äë': 'executive_summary',
            '„Äê‰∏¥Â∫äËØÑ‰º∞„Äë': 'clinical_assessment',
            '„ÄêÈ£éÈô©ËØÑ‰º∞„Äë': 'risk_evaluation',
            '„ÄêÊ≤ªÁñóÂª∫ËÆÆ„Äë': 'treatment_recommendations',
            '„ÄêÁîüÊ¥ªÊñπÂºèÂª∫ËÆÆ„Äë': 'lifestyle_recommendations',
            '„ÄêÁõëÊµãËÆ°Âàí„Äë': 'monitoring_plan',
            '„ÄêÁ¥ßÊÄ•È¢ÑÊ°à„Äë': 'emergency_protocols'
        }
        
        current_section = None
        lines = ai_response.split('\n')
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # Ê£ÄÊü•ÊòØÂê¶ÊòØÊñ∞ÁöÑÁ´†ËäÇ
            section_found = False
            for pattern, section_name in section_patterns.items():
                if pattern in line:
                    current_section = section_name
                    section_found = True
                    # ÊèêÂèñÁ´†ËäÇÊ†áÈ¢òÂêéÁöÑÂÜÖÂÆπ
                    content = line.replace(pattern, '').strip('Ôºö: ')
                    if content:
                        if section_name in ['treatment_recommendations', 'lifestyle_recommendations']:
                            if content.startswith('-'):
                                sections[section_name].append(content[1:].strip())
                            else:
                                sections[section_name].append(content)
                        else:
                            sections[section_name] = content
                    break
            
            if not section_found and current_section:
                # ÁªßÁª≠ÂΩìÂâçÁ´†ËäÇÁöÑÂÜÖÂÆπ
                if current_section in ['treatment_recommendations', 'lifestyle_recommendations']:
                    if line.startswith('-'):
                        sections[current_section].append(line[1:].strip())
                    elif line.startswith(('‚Ä¢', '*', '1.', '2.', '3.', '4.', '5.')):
                        clean_line = line.lstrip('‚Ä¢*123456789. ')
                        sections[current_section].append(clean_line)
                    elif sections[current_section] and not any(x in line for x in ['„Äê', '„Äë']):
                        # Â¶ÇÊûú‰∏çÊòØÊñ∞Á´†ËäÇ‰∏îÊúâÂÜÖÂÆπÔºåËøΩÂä†Âà∞ÊúÄÂêé‰∏Ä‰∏™Âª∫ËÆÆ
                        sections[current_section][-1] += ' ' + line
                else:
                    if sections[current_section]:
                        sections[current_section] += ' ' + line
                    else:
                        sections[current_section] = line
        
        # Ensure required fields are not empty
        if not sections['executive_summary']:
            sections['executive_summary'] = 'Patient requires further evaluation by a professional physician'
        if not sections['clinical_assessment']:
            sections['clinical_assessment'] = 'Comprehensive clinical assessment is recommended'
        if not sections['risk_evaluation']:
            sections['risk_evaluation'] = 'Risk assessment requires professional medical judgment'
        if not sections['treatment_recommendations']:
            sections['treatment_recommendations'] = ['Consult with a psychiatrist to develop a personalized treatment plan']
        if not sections['lifestyle_recommendations']:
            sections['lifestyle_recommendations'] = ['Maintain regular sleep schedule and healthy lifestyle habits']
        if not sections['monitoring_plan']:
            sections['monitoring_plan'] = 'Regular follow-up and symptom monitoring recommended'
        if not sections['emergency_protocols']:
            sections['emergency_protocols'] = 'In case of emergency, contact a physician immediately or call emergency services'

        return sections
    
    def _parse_historical_response(self, ai_response: str) -> Dict:
        """Parse historical analysis AI response"""
        # Define 5 section parsing patterns - support both English and Chinese
        historical_patterns = {
            '[EXECUTIVE SUMMARY]': 'executive_summary',
            '[PROGRESS ANALYSIS]': 'progress_analysis',
            '[TREND INTERPRETATION]': 'trend_interpretation',
            '[TREATMENT RECOMMENDATIONS]': 'treatment_recommendations',
            '[PROGNOSIS ASSESSMENT]': 'prognosis_assessment',
            # Fallback to Chinese patterns for compatibility
            '„ÄêÊâßË°åÊëòË¶Å„Äë': 'executive_summary',
            '„ÄêËøõÂ±ïÂàÜÊûê„Äë': 'progress_analysis',
            '„ÄêË∂ãÂäøËß£ËØª„Äë': 'trend_interpretation',
            '„ÄêÊ≤ªÁñóÂª∫ËÆÆ„Äë': 'treatment_recommendations',
            '„ÄêÈ¢ÑÂêéËØÑ‰º∞„Äë': 'prognosis_assessment'
        }

        # Initialize all fields
        sections = {
            'executive_summary': '',
            'progress_analysis': '',
            'trend_interpretation': '',
            'treatment_recommendations': '',
            'prognosis_assessment': ''
        }
        
        current_section = None
        lines = ai_response.split('\n')
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # Ê£ÄÊü•ÂéÜÂè≤ÂàÜÊûêÁ´†ËäÇ
            for pattern, section_name in historical_patterns.items():
                if pattern in line:
                    current_section = section_name
                    content = line.replace(pattern, '').strip('Ôºö: ')
                    if content:
                        sections[section_name] = content
                    break
            else:
                # ÁªßÁª≠ÂΩìÂâçÂéÜÂè≤ÂàÜÊûêÁ´†ËäÇÁöÑÂÜÖÂÆπ
                if current_section and current_section in historical_patterns.values():
                    if sections[current_section]:
                        sections[current_section] += ' ' + line
                    else:
                        sections[current_section] = line
        
        # Provide default values for empty historical analysis fields
        if not sections['executive_summary']:
            sections['executive_summary'] = 'Based on historical data analysis, overall treatment progress requires continuous monitoring and professional evaluation'
        if not sections['progress_analysis']:
            sections['progress_analysis'] = 'Based on available data, treatment progress requires continuous monitoring and professional evaluation'
        if not sections['trend_interpretation']:
            sections['trend_interpretation'] = 'Symptom trend changes require comprehensive assessment in conjunction with clinical presentation'
        if not sections['treatment_recommendations']:
            sections['treatment_recommendations'] = 'Continue current treatment plan with regular effectiveness assessments'
        if not sections['prognosis_assessment']:
            sections['prognosis_assessment'] = 'Prognosis assessment requires consideration of multiple factors. Regular professional evaluation is recommended'

        return sections
    
    def _save_report(self, report: AdvisorReport, ai_input: Dict, ai_response: str) -> bool:
        """‰øùÂ≠òÊä•ÂëäÂà∞Êï∞ÊçÆÂ∫ì"""
        try:
            conn = self.db_manager._get_connection()
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO ai_advisor_reports (
                    report_id, user_id, report_type, analysis_id, generated_at,
                    executive_summary, clinical_assessment, risk_evaluation,
                    treatment_recommendations, lifestyle_recommendations,
                    monitoring_plan, emergency_protocols,
                    progress_analysis, trend_interpretation, prognosis_assessment,
                    confidence_score, ai_model_version, processing_time,
                    ai_input_data, ai_response_raw
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                report.report_id,
                report.user_id,
                report.report_type,
                report.analysis_id,
                report.generated_at.isoformat(),
                report.executive_summary,
                getattr(report, 'clinical_assessment', ''),
                getattr(report, 'risk_evaluation', ''),
                json.dumps(getattr(report, 'treatment_recommendations', ''), ensure_ascii=False),
                json.dumps(getattr(report, 'lifestyle_recommendations', ''), ensure_ascii=False),
                getattr(report, 'monitoring_plan', ''),
                getattr(report, 'emergency_protocols', ''),
                report.progress_analysis,
                report.trend_interpretation,
                report.prognosis_assessment,
                report.confidence_score,
                report.ai_model_version,
                report.processing_time,
                json.dumps(ai_input, ensure_ascii=False),
                ai_response
            ))
            
            conn.commit()
            print(f"AIÈ°æÈóÆÊä•ÂëäÂ∑≤‰øùÂ≠ò: {report.report_id}")
            return True
            
        except sqlite3.Error as e:
            print(f"‰øùÂ≠òAIÈ°æÈóÆÊä•ÂëäÂ§±Ë¥•: {e}")
            return False
        finally:
            if conn:
                conn.close()
    
    def get_report(self, report_id: str) -> Optional[Dict]:
        """Ëé∑ÂèñÊä•ÂëäËØ¶ÊÉÖ"""
        try:
            conn = self.db_manager._get_connection()
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT * FROM ai_advisor_reports WHERE report_id = ?
            ''', (report_id,))
            
            result = cursor.fetchone()
            
            if result:
                columns = [description[0] for description in cursor.description]
                report_data = dict(zip(columns, result))
                
                # Ëß£ÊûêJSONÂ≠óÊÆµ
                json_fields = ['treatment_recommendations', 'lifestyle_recommendations', 
                             'ai_input_data']
                
                for field in json_fields:
                    if report_data[field]:
                        try:
                            report_data[field] = json.loads(report_data[field])
                        except json.JSONDecodeError:
                            pass
                
                return report_data
            
            return None
            
        except sqlite3.Error as e:
            print(f"Ëé∑ÂèñAIÊä•ÂëäÂ§±Ë¥•: {e}")
            return None
        finally:
            if conn:
                conn.close()
    
    def get_user_reports(self, user_id: str, report_type: Optional[str] = None, limit: int = 10) -> List[Dict]:
        """Ëé∑ÂèñÁî®Êà∑ÁöÑÊä•ÂëäÂéÜÂè≤"""
        try:
            conn = self.db_manager._get_connection()
            cursor = conn.cursor()
            
            query = '''
                SELECT report_id, report_type, generated_at, confidence_score, processing_time
                FROM ai_advisor_reports
                WHERE user_id = ?
            '''
            params = [user_id]
            
            if report_type:
                query += ' AND report_type = ?'
                params.append(report_type)
            
            query += ' ORDER BY generated_at DESC LIMIT ?'
            params.append(limit)
            
            cursor.execute(query, params)
            results = cursor.fetchall()
            
            return [{
                'report_id': row[0],
                'report_type': row[1],
                'generated_at': row[2],
                'confidence_score': row[3],
                'processing_time': row[4]
            } for row in results]
            
        except sqlite3.Error as e:
            print(f"Ëé∑ÂèñÁî®Êà∑Êä•ÂëäÂéÜÂè≤Â§±Ë¥•: {e}")
            return []
        finally:
            if conn:
                conn.close()

# ‰æøÊç∑ÂäüËÉΩÂáΩÊï∞
def generate_quick_report(user_id: str, report_type: str = 'both') -> Dict:
    """Âø´ÈÄüÁîüÊàêÊä•ÂëäÁöÑ‰æøÊç∑ÂáΩÊï∞"""
    db_manager = DatabaseManager()
    analyzer = MDQAnalyzer(db_manager)
    advisor = DeepSeekAdvisor(db_manager, analyzer)
    
    results = {}
    
    try:
        if report_type in ['single', 'both']:
            # Ëé∑ÂèñÊúÄÊñ∞ÂàÜÊûêID
            analysis_history = analyzer.get_analysis_history(user_id, limit=1)
            if analysis_history:
                analysis_id = analysis_history[0]['analysis_id']
                single_report = advisor.generate_single_test_report(analysis_id)
                results['single_test_report'] = {
                    'report_id': single_report.report_id,
                    'executive_summary': single_report.executive_summary,
                    'treatment_recommendations': single_report.treatment_recommendations,
                    'emergency_protocols': single_report.emergency_protocols
                }
        
        if report_type in ['historical', 'both']:
            historical_report = advisor.generate_historical_analysis_report(user_id)
            results['historical_report'] = {
                'report_id': historical_report.report_id,
                'progress_analysis': historical_report.progress_analysis,
                'trend_interpretation': historical_report.trend_interpretation,
                'prognosis_assessment': historical_report.prognosis_assessment
            }
        
        return {'success': True, 'reports': results}
        
    except Exception as e:
        return {'success': False, 'error': str(e)}

def batch_generate_reports(report_type: str = 'both') -> Dict:
    """ÊâπÈáè‰∏∫ÊâÄÊúâÁî®Êà∑ÁîüÊàêÊä•Âëä"""
    db_manager = DatabaseManager()
    analyzer = MDQAnalyzer(db_manager)
    advisor = DeepSeekAdvisor(db_manager, analyzer)
    
    try:
        conn = db_manager._get_connection()
        cursor = conn.cursor()
        
        # Ëé∑ÂèñÊâÄÊúâÊúâÂàÜÊûêËÆ∞ÂΩïÁöÑÁî®Êà∑
        cursor.execute('''
            SELECT DISTINCT user_id FROM mdq_analysis_results
        ''')
        
        user_ids = [row[0] for row in cursor.fetchall()]
        
        results = {
            'total_users': len(user_ids),
            'successful_reports': 0,
            'failed_reports': 0,
            'reports': {}
        }
        
        for user_id in user_ids:
            try:
                user_results = generate_quick_report(user_id, report_type)
                if user_results['success']:
                    results['successful_reports'] += 1
                    results['reports'][user_id] = user_results['reports']
                else:
                    results['failed_reports'] += 1
                    print(f"Áî®Êà∑ {user_id[:8]} Êä•ÂëäÁîüÊàêÂ§±Ë¥•: {user_results['error']}")
                    
            except Exception as e:
                results['failed_reports'] += 1
                print(f"Áî®Êà∑ {user_id[:8]} Êä•ÂëäÁîüÊàêÂá∫Èîô: {e}")
        
        return results
        
    except Exception as e:
        return {'success': False, 'error': str(e)}
        
    finally:
        if conn:
            conn.close()

# Êä•ÂëäÊ†ºÂºèÂåñÂíåÂØºÂá∫ÂäüËÉΩ
def format_report_for_display(report_data: Dict) -> str:
    """Ê†ºÂºèÂåñÊä•ÂëäÁî®‰∫éÊòæÁ§∫"""
    if not report_data:
        return "Êä•Âëä‰∏çÂ≠òÂú®"
    
    report_type_names = {
        'single_test': 'ÂçïÊ¨°ÊµãËØïÂàÜÊûêÊä•Âëä',
        'historical_analysis': 'ÂéÜÂè≤Ë∂ãÂäøÂàÜÊûêÊä•Âëä'
    }
    
    formatted_text = f"""
# {report_type_names.get(report_data['report_type'], 'ÂàÜÊûêÊä•Âëä')}

**Êä•ÂëäID:** {report_data['report_id']}
**ÁîüÊàêÊó∂Èó¥:** {report_data['generated_at'][:19]}
**AIÊ®°Âûã:** {report_data['ai_model_version']}
**ÁΩÆ‰ø°Â∫¶:** {report_data['confidence_score']:.2f}
**Â§ÑÁêÜÊó∂Èó¥:** {report_data['processing_time']:.2f}Áßí

---

## üìã ÊâßË°åÊëòË¶Å
{report_data['executive_summary']}

## üè• ‰∏¥Â∫äËØÑ‰º∞
{report_data['clinical_assessment']}

## ‚ö†Ô∏è È£éÈô©ËØÑ‰º∞
{report_data['risk_evaluation']}

## üíä Ê≤ªÁñóÂª∫ËÆÆ
"""
    
    # Â§ÑÁêÜÊ≤ªÁñóÂª∫ËÆÆ
    treatment_recs = report_data['treatment_recommendations']
    if isinstance(treatment_recs, list):
        for i, rec in enumerate(treatment_recs, 1):
            formatted_text += f"{i}. {rec}\n"
    else:
        formatted_text += f"{treatment_recs}\n"
    
    formatted_text += "\n## üí° ÁîüÊ¥ªÊñπÂºèÂª∫ËÆÆ\n"
    
    # Â§ÑÁêÜÁîüÊ¥ªÊñπÂºèÂª∫ËÆÆ
    lifestyle_recs = report_data['lifestyle_recommendations']
    if isinstance(lifestyle_recs, list):
        for i, rec in enumerate(lifestyle_recs, 1):
            formatted_text += f"{i}. {rec}\n"
    else:
        formatted_text += f"{lifestyle_recs}\n"
    
    formatted_text += f"""
## üìÖ ÁõëÊµãËÆ°Âàí
{report_data['monitoring_plan']}

## üö® Á¥ßÊÄ•È¢ÑÊ°à
{report_data['emergency_protocols']}
"""
    
    # Â¶ÇÊûúÊòØÂéÜÂè≤ÂàÜÊûêÊä•ÂëäÔºåÊ∑ªÂä†È¢ùÂ§ñÂÜÖÂÆπ
    if report_data['report_type'] == 'historical_analysis':
        formatted_text += f"""
---

## üìà ËøõÂ±ïÂàÜÊûê
{report_data['progress_analysis']}

## üìä Ë∂ãÂäøËß£ËØª
{report_data['trend_interpretation']}

## üîÆ È¢ÑÂêéËØÑ‰º∞
{report_data['prognosis_assessment']}
"""
    
    return formatted_text

def export_report_to_file(report_id: str, filename: Optional[str] = None) -> str:
    """ÂØºÂá∫Êä•ÂëäÂà∞Êñá‰ª∂"""
    db_manager = DatabaseManager()
    analyzer = MDQAnalyzer(db_manager)
    advisor = DeepSeekAdvisor(db_manager, analyzer)
    
    report = advisor.get_report(report_id)
    if not report:
        return "Êä•Âëä‰∏çÂ≠òÂú®"
    
    if filename is None:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"mdq_report_{report_id[:8]}_{timestamp}.txt"
    
    formatted_text = format_report_for_display(report)
    
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(formatted_text)
        return f"Êä•ÂëäÂ∑≤ÂØºÂá∫Âà∞: {filename}"
    except Exception as e:
        return f"ÂØºÂá∫Â§±Ë¥•: {e}"

# ÊµãËØïÂáΩÊï∞
def test_deepseek_advisor():
    """ÊµãËØïDeepSeek AIÈ°æÈóÆÂäüËÉΩ"""
    print("=== DeepSeek AI È°æÈóÆÁ≥ªÁªüÊµãËØï ===")
    
    # Ê£ÄÊü•APIÂØÜÈí•ËÆæÁΩÆ
    if DEEPSEEK_API_KEY == "your_deepseek_api_key_here":
        print("‚ùå ËØ∑ÂÖàÂú®Êñá‰ª∂È°∂ÈÉ®ËÆæÁΩÆÊúâÊïàÁöÑ DeepSeek API ÂØÜÈí•")
        print("ËØ∑‰øÆÊîπÊñá‰ª∂È°∂ÈÉ®ÁöÑ DEEPSEEK_API_KEY ÂèòÈáè")
        print("Ëé∑ÂèñAPIÂØÜÈí•: https://platform.deepseek.com/")
        return
    
    # ÂàùÂßãÂåñÁªÑ‰ª∂
    try:
        db_manager = DatabaseManager()
        analyzer = MDQAnalyzer(db_manager)
        advisor = DeepSeekAdvisor(db_manager, analyzer)
        print("‚úÖ AIÈ°æÈóÆÁ≥ªÁªüÂàùÂßãÂåñÊàêÂäü")
    except Exception as e:
        print(f"‚ùå ÂàùÂßãÂåñÂ§±Ë¥•: {e}")
        return
    
    # Êü•ÊâæÁé∞ÊúâÁî®Êà∑ËøõË°åÊµãËØï
    try:
        conn = db_manager._get_connection()
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT DISTINCT ar.user_id, ar.analysis_id, u.username
            FROM mdq_analysis_results ar
            JOIN users u ON ar.user_id = u.user_id
            ORDER BY ar.analysis_date DESC
            LIMIT 1
        ''')
        
        result = cursor.fetchone()
        
        if not result:
            print("‚ùå Ê≤°ÊúâÊâæÂà∞ÂàÜÊûêÁªìÊûúÔºåËØ∑ÂÖàËøêË°å analyse.py ÁîüÊàêÂàÜÊûêÊï∞ÊçÆ")
            return
        
        user_id, analysis_id, username = result
        print(f"ÊµãËØïÁî®Êà∑: {username} (ID: {user_id[:8]}...)")
        print(f"ÂàÜÊûêID: {analysis_id[:8]}...")
        
        # ÊµãËØï1: ÁîüÊàêÂçïÊ¨°ÂàÜÊûêÊä•Âëä
        print(f"\n=== ÊµãËØï1: ÁîüÊàêÂçïÊ¨°ÊµãËØïÂàÜÊûêÊä•Âëä ===")
        try:
            print("Ê≠£Âú®Ë∞ÉÁî®DeepSeek APIÁîüÊàêÊä•Âëä...")
            single_report = advisor.generate_single_test_report(analysis_id)
            
            print("‚úÖ ÂçïÊ¨°ÂàÜÊûêÊä•ÂëäÁîüÊàêÊàêÂäü!")
            print(f"Êä•ÂëäID: {single_report.report_id}")
            print(f"Â§ÑÁêÜÊó∂Èó¥: {single_report.processing_time:.2f}Áßí")
            print(f"ÁΩÆ‰ø°Â∫¶: {single_report.confidence_score:.2f}")
            
            print(f"\nüìã ÊâßË°åÊëòË¶Å:")
            print(f"{single_report.executive_summary}")
            
            print(f"\nüè• Ê≤ªÁñóÂª∫ËÆÆ:")
            for i, rec in enumerate(single_report.treatment_recommendations[:3], 1):
                print(f"  {i}. {rec}")
            
            print(f"\nüí° ÁîüÊ¥ªÊñπÂºèÂª∫ËÆÆ:")
            for i, rec in enumerate(single_report.lifestyle_recommendations[:3], 1):
                print(f"  {i}. {rec}")
                
        except Exception as e:
            print(f"‚ùå ÂçïÊ¨°ÂàÜÊûêÊä•ÂëäÁîüÊàêÂ§±Ë¥•: {e}")
            print("ËØ∑Ê£ÄÊü•APIÂØÜÈí•ÊòØÂê¶Ê≠£Á°ÆÔºå‰ª•ÂèäÁΩëÁªúËøûÊé•ÊòØÂê¶Ê≠£Â∏∏")
        
        # ÊµãËØï2: ÁîüÊàêÂéÜÂè≤ÂàÜÊûêÊä•Âëä
        print(f"\n=== ÊµãËØï2: ÁîüÊàêÂéÜÂè≤Ë∂ãÂäøÂàÜÊûêÊä•Âëä ===")
        try:
            print("Ê≠£Âú®Ë∞ÉÁî®DeepSeek APIÁîüÊàêÂéÜÂè≤ÂàÜÊûêÊä•Âëä...")
            historical_report = advisor.generate_historical_analysis_report(user_id)
            
            print("‚úÖ ÂéÜÂè≤ÂàÜÊûêÊä•ÂëäÁîüÊàêÊàêÂäü!")
            print(f"Êä•ÂëäID: {historical_report.report_id}")
            print(f"Â§ÑÁêÜÊó∂Èó¥: {historical_report.processing_time:.2f}Áßí")
            print(f"ÁΩÆ‰ø°Â∫¶: {historical_report.confidence_score:.2f}")
            
            print(f"\nüìà ËøõÂ±ïÂàÜÊûê:")
            print(f"{historical_report.progress_analysis[:200]}...")
            
            print(f"\nüìä Ë∂ãÂäøËß£ËØª:")
            print(f"{historical_report.trend_interpretation[:200]}...")
            
            print(f"\nüîÆ È¢ÑÂêéËØÑ‰º∞:")
            print(f"{historical_report.prognosis_assessment[:200]}...")
            
        except Exception as e:
            print(f"‚ùå ÂéÜÂè≤ÂàÜÊûêÊä•ÂëäÁîüÊàêÂ§±Ë¥•: {e}")
        
        # ÊµãËØï3: Êä•ÂëäËé∑ÂèñÂäüËÉΩ
        print(f"\n=== ÊµãËØï3: Êä•ÂëäËé∑ÂèñÂäüËÉΩ ===")
        user_reports = advisor.get_user_reports(user_id)
        print(f"Áî®Êà∑Êä•ÂëäÂéÜÂè≤: {len(user_reports)} ‰∏™")
        
        for report in user_reports:
            print(f"  - {report['report_type']}: {report['generated_at'][:19]} "
                  f"(ÁΩÆ‰ø°Â∫¶: {report['confidence_score']:.2f}, "
                  f"Â§ÑÁêÜÊó∂Èó¥: {report['processing_time']:.2f}s)")
        
        # ÊµãËØï4: Êä•ÂëäÊ†ºÂºèÂåñ
        if user_reports:
            print(f"\n=== ÊµãËØï4: Êä•ÂëäÊ†ºÂºèÂåñ ===")
            latest_report_id = user_reports[0]['report_id']
            report_detail = advisor.get_report(latest_report_id)
            
            if report_detail:
                formatted_report = format_report_for_display(report_detail)
                print("‚úÖ Êä•ÂëäÊ†ºÂºèÂåñÊàêÂäü")
                print(f"Ê†ºÂºèÂåñÊä•ÂëäÈïøÂ∫¶: {len(formatted_report)} Â≠óÁ¨¶")
                
                # ÊòæÁ§∫Êä•ÂëäÊëòË¶Å
                lines = formatted_report.split('\n')
                for line in lines[:15]:  # ÊòæÁ§∫Ââç15Ë°å
                    print(line)
                print("...")
            else:
                print("‚ùå Ëé∑ÂèñÊä•ÂëäËØ¶ÊÉÖÂ§±Ë¥•")
        
        print(f"\nüéâ AIÈ°æÈóÆÁ≥ªÁªüÊµãËØïÂÆåÊàê!")
        print("‚úÖ ÂçïÊ¨°ÊµãËØïÊä•ÂëäÁîüÊàêÂäüËÉΩÊ≠£Â∏∏")
        print("‚úÖ ÂéÜÂè≤ÂàÜÊûêÊä•ÂëäÁîüÊàêÂäüËÉΩÊ≠£Â∏∏") 
        print("‚úÖ Êï∞ÊçÆÂ∫ì‰øùÂ≠òÂäüËÉΩÊ≠£Â∏∏")
        print("‚úÖ Êä•ÂëäËé∑ÂèñÂäüËÉΩÊ≠£Â∏∏")
        print("‚úÖ Êä•ÂëäÊ†ºÂºèÂåñÂäüËÉΩÊ≠£Â∏∏")
        
    except Exception as e:
        print(f"‚ùå ÊµãËØïËøáÁ®ãÂá∫Èîô: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        if conn:
            conn.close()

# Âø´ÈÄüÊºîÁ§∫ÂáΩÊï∞
def demo_advisor_workflow(user_id: str = None):
    """ÊºîÁ§∫AIÈ°æÈóÆÂÆåÊï¥Â∑•‰ΩúÊµÅÁ®ã"""
    print("=== AIÈ°æÈóÆÂ∑•‰ΩúÊµÅÁ®ãÊºîÁ§∫ ===")
    
    if DEEPSEEK_API_KEY == "your_deepseek_api_key_here":
        print("‚ùå ËØ∑ÂÖàËÆæÁΩÆAPIÂØÜÈí•")
        return
    
    db_manager = DatabaseManager()
    analyzer = MDQAnalyzer(db_manager)
    
    # Â¶ÇÊûúÊ≤°ÊúâÊåáÂÆöÁî®Êà∑ÔºåËá™Âä®ÈÄâÊã©
    if not user_id:
        try:
            conn = db_manager._get_connection()
            cursor = conn.cursor()
            cursor.execute('SELECT DISTINCT user_id FROM mdq_analysis_results LIMIT 1')
            result = cursor.fetchone()
            if result:
                user_id = result[0]
            else:
                print("‚ùå Ê≤°ÊúâÊâæÂà∞Áî®Êà∑Êï∞ÊçÆ")
                return
        finally:
            if conn:
                conn.close()
    
    try:
        advisor = DeepSeekAdvisor(db_manager, analyzer)
        
        print(f"Áî®Êà∑ID: {user_id[:8]}...")
        
        # ÁîüÊàê‰∏§ÁßçÁ±ªÂûãÁöÑÊä•Âëä
        print("\n1. ÁîüÊàêÂçïÊ¨°ÊµãËØïÊä•Âëä...")
        single_result = generate_quick_report(user_id, 'single')
        
        print("2. ÁîüÊàêÂéÜÂè≤ÂàÜÊûêÊä•Âëä...")
        historical_result = generate_quick_report(user_id, 'historical')
        
        # ÊòæÁ§∫ÁªìÊûúÊëòË¶Å
        if single_result['success']:
            single_id = single_result['reports']['single_test_report']['report_id']
            print(f"‚úÖ ÂçïÊ¨°Êä•ÂëäÁîüÊàê: {single_id[:8]}...")
        
        if historical_result['success']:
            historical_id = historical_result['reports']['historical_report']['report_id'] 
            print(f"‚úÖ ÂéÜÂè≤Êä•ÂëäÁîüÊàê: {historical_id[:8]}...")
        
        print("\nüìä Â∑•‰ΩúÊµÅÁ®ãÊºîÁ§∫ÂÆåÊàê!")
        
    except Exception as e:
        print(f"‚ùå ÊºîÁ§∫Â§±Ë¥•: {e}")

if __name__ == "__main__":
    # ËøêË°åÊµãËØï
    test_deepseek_advisor()
    
    # ÂèØ‰ª•ÂèñÊ∂àÊ≥®Èáä‰∏ãÈù¢ÁöÑË°åÊù•ËøêË°åÂÖ∂‰ªñÂäüËÉΩ
    # demo_advisor_workflow()  # ÊºîÁ§∫ÂÆåÊï¥Â∑•‰ΩúÊµÅÁ®ã
    # batch_generate_reports('both')  # ÊâπÈáèÁîüÊàêÊâÄÊúâÁî®Êà∑Êä•Âëä