# ====== DeepSeek API é…ç½® ======
# è¯·åœ¨è¿™é‡Œè®¾ç½®æ‚¨çš„ DeepSeek API å¯†é’¥
DEEPSEEK_API_KEY = "sk-cb387c428d9343328cea734e6ae0f9f5"

# ====== å¯¼å…¥ä¾èµ– ======
# Please install OpenAI SDK first: `pip3 install openai`
from openai import OpenAI
import json
import sqlite3
from datetime import datetime
from typing import Dict, List, Optional
from dataclasses import dataclass
import uuid
import time
from database import DatabaseManager
from analyse import MDQAnalyzer

@dataclass
class AdvisorReport:
    """AIé¡¾é—®æŠ¥å‘Šæ•°æ®ç±»"""
    report_id: str
    user_id: str
    report_type: str  # 'single_test' æˆ– 'historical_analysis'
    analysis_id: Optional[str]  # å•æ¬¡åˆ†æIDï¼ˆå•æµ‹è¯•æŠ¥å‘Šï¼‰
    generated_at: datetime
    
    # AIç”Ÿæˆçš„æŠ¥å‘Šå†…å®¹
    executive_summary: str
    clinical_assessment: Optional[str] = None
    risk_evaluation: Optional[str] = None
    treatment_recommendations: Optional[str] = None
    lifestyle_recommendations: Optional[str] = None
    monitoring_plan: Optional[str] = None
    emergency_protocols: Optional[str] = None
    
    # åŸºäºå†å²çš„å†…å®¹ï¼ˆå†å²åˆ†ææŠ¥å‘Šï¼‰
    progress_analysis: Optional[str] = None
    trend_interpretation: Optional[str] = None
    prognosis_assessment: Optional[str] = None
    
    # å…ƒæ•°æ®
    confidence_score: float = 0.0
    ai_model_version: str = "deepseek-chat"
    processing_time: float = 0.0

class DeepSeekAdvisor:
    """DeepSeek AI åˆ†æé¡¾é—®"""
    
    def __init__(self, db_manager: DatabaseManager, analyzer: MDQAnalyzer):
        self.db_manager = db_manager
        self.analyzer = analyzer
        
        # éªŒè¯APIå¯†é’¥
        if DEEPSEEK_API_KEY == "your_deepseek_api_key_here":
            raise ValueError("è¯·åœ¨æ–‡ä»¶é¡¶éƒ¨è®¾ç½®æœ‰æ•ˆçš„ DeepSeek API å¯†é’¥")
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        self.client = OpenAI(
            api_key=DEEPSEEK_API_KEY, 
            base_url="https://api.deepseek.com"
        )
        
        self._init_database_tables()
        
        # AIæç¤ºè¯æ¨¡æ¿
        self.prompts = {
            'single_test': {
                'system': """ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„ç²¾ç¥ç§‘åŒ»ç”Ÿå’ŒåŒç›¸æƒ…æ„Ÿéšœç¢ä¸“å®¶ã€‚ä½ éœ€è¦åŸºäºæ‚£è€…çš„MDQé—®å·åˆ†æç»“æœï¼Œç”Ÿæˆä¸“ä¸šçš„ä¸´åºŠè¯„ä¼°æŠ¥å‘Šå’Œæ²»ç–—å»ºè®®ã€‚

è¯·ä»¥ä¸“ä¸šã€å®¢è§‚ã€å…³æ€€çš„è¯­è°ƒæä¾›ä»¥ä¸‹7ä¸ªéƒ¨åˆ†çš„åˆ†æï¼ˆè¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼‰ï¼š

ã€æ‰§è¡Œæ‘˜è¦ã€‘ï¼šç®€æ´æ¦‚è¿°æ‚£è€…å½“å‰çŠ¶æ€ï¼ˆ2-3å¥è¯ï¼‰
ã€ä¸´åºŠè¯„ä¼°ã€‘ï¼šè¯¦ç»†åˆ†æç—‡çŠ¶è¡¨ç°å’Œä¸¥é‡ç¨‹åº¦
ã€é£é™©è¯„ä¼°ã€‘ï¼šè¯„ä¼°å½“å‰é£é™©å’Œæ½œåœ¨å±é™©
ã€æ²»ç–—å»ºè®®ã€‘ï¼šå…·ä½“çš„åŒ»ç–—å¹²é¢„å»ºè®®ï¼ˆæ¯æ¡å»ºè®®ç‹¬ç«‹ä¸€è¡Œï¼Œä»¥"-"å¼€å¤´ï¼‰
ã€ç”Ÿæ´»æ–¹å¼å»ºè®®ã€‘ï¼šæ—¥å¸¸ç®¡ç†å’Œè‡ªæˆ‘æŠ¤ç†ï¼ˆæ¯æ¡å»ºè®®ç‹¬ç«‹ä¸€è¡Œï¼Œä»¥"-"å¼€å¤´ï¼‰
ã€ç›‘æµ‹è®¡åˆ’ã€‘ï¼šåç»­è·Ÿè¸ªå’Œè¯„ä¼°è®¡åˆ’
ã€ç´§æ€¥é¢„æ¡ˆã€‘ï¼šå±æœºæƒ…å†µçš„åº”å¯¹æªæ–½

è¯·ç¡®ä¿å»ºè®®åŸºäºå¾ªè¯åŒ»å­¦ï¼Œç¬¦åˆä¸´åºŠå®è·µæŒ‡å—ã€‚""",
                
                'user_template': """è¯·ä¸ºä»¥ä¸‹æ‚£è€…ç”ŸæˆMDQåˆ†ææŠ¥å‘Šï¼š

**æ‚£è€…åŸºæœ¬ä¿¡æ¯ï¼š**
- å¹´é¾„ï¼š{age}å²
- æ€§åˆ«ï¼š{gender}
- è¯„ä¼°æ€»æ•°ï¼š{total_assessments}æ¬¡
- è¯„ä¼°æ—¶é—´è·¨åº¦ï¼š{assessment_span_days}å¤©

**å½“å‰ä¸´åºŠçŠ¶æ€ï¼š**
- MDQåˆ†æ•°ï¼š{mdq_score}/13
- åŠ æƒåˆ†æ•°ï¼š{weighted_score}
- ä¸¥é‡ç¨‹åº¦ç­‰çº§ï¼š{severity_level}
- é£é™©ç™¾åˆ†æ¯”ï¼š{risk_percentage}%
- åŠŸèƒ½æŸå®³ï¼š{functional_impairment}

**ç—‡çŠ¶åˆ†å¸ƒï¼š**
{symptom_distribution}

**åŒç›¸é£é™©æŒ‡æ ‡ï¼š**
{bipolar_risk_profile}

**é˜³æ€§ç—‡çŠ¶ï¼š**
{positive_symptoms}

**ç´§æ€¥æƒ…å†µæ ‡è¯†ï¼š**{emergency_indicators}

**ç›‘æµ‹ä¼˜å…ˆçº§ï¼š**{monitoring_priorities}

**å¹²é¢„ç›®æ ‡ï¼š**{intervention_targets}

è¯·ç”Ÿæˆå®Œæ•´çš„ä¸´åºŠè¯„ä¼°æŠ¥å‘Šå’Œæ²»ç–—å»ºè®®ã€‚"""
            },
            
            'historical': {
                'system': """ä½ æ˜¯ä¸€ä½ç²¾ç¥ç§‘åŒ»ç”Ÿï¼Œä¸“é—¨ä»äº‹åŒç›¸æƒ…æ„Ÿéšœç¢çš„é•¿æœŸæ²»ç–—å’Œç®¡ç†ã€‚ä½ éœ€è¦åŸºäºæ‚£è€…çš„å†å²MDQè¯„ä¼°æ•°æ®ï¼Œåˆ†ææ²»ç–—è¿›å±•å’Œé¢„åï¼Œæä¾›ç»¼åˆæ€§çš„é•¿æœŸæ²»ç–—å»ºè®®ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡º5ä¸ªéƒ¨åˆ†çš„åˆ†æï¼š

ã€æ‰§è¡Œæ‘˜è¦ã€‘ï¼šç®€æ´æ¦‚è¿°æ‚£è€…æ•´ä½“æ²»ç–—è¿›å±•å’Œå½“å‰çŠ¶æ€ï¼ˆ2-3å¥è¯ï¼‰
ã€è¿›å±•åˆ†æã€‘ï¼šæ²»ç–—æ•ˆæœå’Œç—‡çŠ¶å˜åŒ–è½¨è¿¹åˆ†æï¼ŒåŒ…æ‹¬æ”¹å–„è¶‹åŠ¿å’Œä¸€è‡´æ€§è¯„ä¼°
ã€è¶‹åŠ¿è§£è¯»ã€‘ï¼šç—‡çŠ¶è¶‹åŠ¿çš„ä¸“ä¸šè§£è¯»å’Œé¢„æµ‹ï¼ŒåŸºäºå†å²æ•°æ®çš„å˜åŒ–æ¨¡å¼
ã€æ²»ç–—å»ºè®®ã€‘ï¼šåŸºäºå†å²åˆ†æçš„å…·ä½“åŒ»ç–—å¹²é¢„å’Œç”Ÿæ´»æ–¹å¼å»ºè®®ï¼ˆæ¯æ¡å»ºè®®ç‹¬ç«‹ä¸€è¡Œï¼Œä»¥"-"å¼€å¤´ï¼‰
ã€é¢„åè¯„ä¼°ã€‘ï¼šé•¿æœŸé¢„åå’Œåº·å¤å¯èƒ½æ€§è¯„ä¼°ï¼ŒåŒ…æ‹¬é£é™©å› ç´ å’Œä¿æŠ¤å› ç´ 

è¯·åŸºäºå¾ªè¯åŒ»å­¦å’Œé•¿æœŸç®¡ç†æœ€ä½³å®è·µæä¾›å»ºè®®ã€‚""",
                
                'user_template': """è¯·ä¸ºä»¥ä¸‹æ‚£è€…ç”Ÿæˆå†å²è¶‹åŠ¿åˆ†ææŠ¥å‘Šï¼š

**æ‚£è€…åŸºæœ¬ä¿¡æ¯ï¼š**
- å¹´é¾„ï¼š{age}å²
- æ€§åˆ«ï¼š{gender}
- è¯„ä¼°æ€»æ•°ï¼š{total_assessments}æ¬¡
- æ—¶é—´è·¨åº¦ï¼š{assessment_span_days}å¤©

**å½“å‰çŠ¶æ€ï¼š**
- å½“å‰MDQåˆ†æ•°ï¼š{current_score}/13
- ä¸¥é‡ç¨‹åº¦ï¼š{severity_level}
- é£é™©ç™¾åˆ†æ¯”ï¼š{risk_percentage}%

**å†å²è½¨è¿¹ï¼š**
- æ”¹å–„è¶‹åŠ¿ï¼š{improvement_trend}
- è¶‹åŠ¿ç½®ä¿¡åº¦ï¼š{trend_confidence}
- å†å²åŸºçº¿ï¼š{baseline_score}
- æ”¹å–„ç™¾åˆ†æ¯”ï¼š{improvement_percentage}%
- ä¸€è‡´æ€§è¯„åˆ†ï¼š{consistency_score}

**åˆ†æ•°æ—¶é—´çº¿ï¼š**
{score_timeline}

**æ²»ç–—ååº”æŒ‡æ ‡ï¼š**
{treatment_indicators}

**æ¢å¤æŒ‡æ ‡ï¼š**
{recovery_indicators}

**å½“å‰é£é™©å› ç´ ï¼š**
{current_risk_factors}

**é¢„åå› ç´ ï¼š**
- ç§¯æå› ç´ ï¼š{positive_factors}
- æ¶ˆæå› ç´ ï¼š{negative_factors}

**ç»Ÿè®¡ç‰¹å¾ï¼š**
- å¹³å‡åˆ†æ•°ï¼š{score_mean}
- æ ‡å‡†å·®ï¼š{score_std}
- åˆ†æ•°èŒƒå›´ï¼š{score_range}
- å˜å¼‚ç³»æ•°ï¼š{variability_coefficient}

è¯·åŸºäºè¿™äº›å†å²æ•°æ®ï¼Œç”Ÿæˆç»¼åˆæ€§çš„è¿›å±•è¯„ä¼°æŠ¥å‘Šå’Œé•¿æœŸæ²»ç–—å»ºè®®ã€‚"""
            }
        }
    
    def _init_database_tables(self):
        """åˆå§‹åŒ–AIé¡¾é—®æŠ¥å‘Šæ•°æ®åº“è¡¨"""
        try:
            conn = self.db_manager._get_connection()
            cursor = conn.cursor()
            
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS ai_advisor_reports (
                    report_id TEXT PRIMARY KEY,
                    user_id TEXT NOT NULL,
                    report_type TEXT NOT NULL CHECK(report_type IN ('single_test', 'historical_analysis')),
                    analysis_id TEXT,
                    generated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    
                    -- AIç”Ÿæˆçš„å†…å®¹
                    executive_summary TEXT NOT NULL,
                    clinical_assessment TEXT NOT NULL,
                    risk_evaluation TEXT NOT NULL,
                    treatment_recommendations TEXT NOT NULL,
                    lifestyle_recommendations TEXT NOT NULL,
                    monitoring_plan TEXT NOT NULL,
                    emergency_protocols TEXT NOT NULL,
                    
                    -- å†å²åˆ†æç‰¹æœ‰å†…å®¹
                    progress_analysis TEXT,
                    trend_interpretation TEXT,
                    prognosis_assessment TEXT,
                    
                    -- å…ƒæ•°æ®
                    confidence_score REAL DEFAULT 0.0,
                    ai_model_version TEXT DEFAULT 'deepseek-chat',
                    processing_time REAL DEFAULT 0.0,
                    
                    -- åŸå§‹æ•°æ®
                    ai_input_data TEXT,
                    ai_response_raw TEXT,
                    
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    
                    FOREIGN KEY (user_id) REFERENCES users (user_id) ON DELETE CASCADE,
                    FOREIGN KEY (analysis_id) REFERENCES mdq_analysis_results (analysis_id) ON DELETE SET NULL
                )
            ''')
            
            # åˆ›å»ºç´¢å¼•
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_advisor_user_type ON ai_advisor_reports(user_id, report_type)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_advisor_generated_at ON ai_advisor_reports(generated_at)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_advisor_analysis_id ON ai_advisor_reports(analysis_id)')
            
            conn.commit()
            print("AIé¡¾é—®æŠ¥å‘Šæ•°æ®åº“è¡¨åˆå§‹åŒ–å®Œæˆ")
            
        except sqlite3.Error as e:
            print(f"AIé¡¾é—®æ•°æ®åº“è¡¨åˆå§‹åŒ–å¤±è´¥: {e}")
        finally:
            if conn:
                conn.close()
    
    def generate_single_test_report(self, analysis_id: str) -> AdvisorReport:
        """ç”Ÿæˆå•æ¬¡æµ‹è¯•åˆ†ææŠ¥å‘Š - ä¿®å¤ç‰ˆ"""
        start_time = time.time()
        
        try:
            # è·å–åˆ†ææ•°æ®
            analysis_detail = self.analyzer.get_analysis_detail(analysis_id)
            if not analysis_detail:
                raise ValueError(f"åˆ†æè®°å½• {analysis_id} ä¸å­˜åœ¨")
            
            ai_data = self.analyzer.get_ai_analysis_data(analysis_id)
            if not ai_data:
                # å¦‚æœæ²¡æœ‰AIæ•°æ®ï¼Œå°è¯•ä»analysis_detailæ„é€ 
                print(f"è­¦å‘Šï¼šæ²¡æœ‰æ‰¾åˆ°AIåˆ†ææ•°æ®ï¼Œå°è¯•ä»åˆ†æè¯¦æƒ…æ„é€ åŸºç¡€æ•°æ®")
                ai_data = {
                    'mdq_part1_score': analysis_detail.get('mdq_part1_score', 0),
                    'has_co_occurrence': analysis_detail.get('has_co_occurrence', False),
                    'functional_impact_level': analysis_detail.get('functional_impact_level', 'no_problems'),
                    'mdq_result': analysis_detail.get('mdq_result', 'negative'),
                    'severity_level': analysis_detail.get('severity_level', 'negative'),
                    'risk_percentage': analysis_detail.get('risk_percentage', 0),
                    'positive_symptoms': json.loads(analysis_detail.get('positive_symptoms', '[]')) if analysis_detail.get('positive_symptoms') else [],
                    'core_symptoms_count': analysis_detail.get('core_symptoms_count', 0)
                }
            
            user_id = analysis_detail['user_id']
            
            # å‡†å¤‡AIè¾“å…¥æ•°æ®
            ai_input = self._prepare_single_test_input(ai_data)
            print(f"AIè¾“å…¥æ•°æ®å‡†å¤‡å®Œæˆ: MDQåˆ†æ•°={ai_input['mdq_score']}, é£é™©={ai_input['risk_percentage']}%")
            
            # è°ƒç”¨DeepSeek API
            user_prompt = self.prompts['single_test']['user_template'].format(**ai_input)
            
            try:
                ai_response = self._call_deepseek_api(
                    self.prompts['single_test']['system'],
                    user_prompt
                )
                print(f"DeepSeek APIè°ƒç”¨æˆåŠŸï¼Œå“åº”é•¿åº¦: {len(ai_response)}")
            except Exception as api_error:
                print(f"DeepSeek APIè°ƒç”¨å¤±è´¥: {api_error}")
                # ç”Ÿæˆå¤‡ç”¨æŠ¥å‘Š
                ai_response = self._generate_fallback_report(ai_input)
            
            # è§£æAIå“åº”
            parsed_response = self._parse_single_test_response(ai_response)
            
            # è®¡ç®—å¤„ç†æ—¶é—´
            processing_time = time.time() - start_time
            
            # åˆ›å»ºæŠ¥å‘Šå¯¹è±¡
            report = AdvisorReport(
                report_id=str(uuid.uuid4()),
                user_id=user_id,
                report_type='single_test',
                analysis_id=analysis_id,
                generated_at=datetime.now(),
                
                executive_summary=parsed_response['executive_summary'],
                clinical_assessment=parsed_response['clinical_assessment'],
                risk_evaluation=parsed_response['risk_evaluation'],
                treatment_recommendations=parsed_response['treatment_recommendations'],
                lifestyle_recommendations=parsed_response['lifestyle_recommendations'],
                monitoring_plan=parsed_response['monitoring_plan'],
                emergency_protocols=parsed_response['emergency_protocols'],
                
                confidence_score=parsed_response.get('confidence_score', 0.8),
                processing_time=processing_time
            )
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            self._save_report(report, ai_input, ai_response)
            
            return report
            
        except Exception as e:
            print(f"ç”Ÿæˆå•æ¬¡æµ‹è¯•æŠ¥å‘Šå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise e
    def _generate_fallback_report(self, ai_input: Dict) -> str:
        """ç”Ÿæˆå¤‡ç”¨æŠ¥å‘Šï¼ˆå½“APIè°ƒç”¨å¤±è´¥æ—¶ï¼‰"""
        mdq_score = ai_input.get('mdq_score', 0)
        risk_percentage = ai_input.get('risk_percentage', 0)
        
        if mdq_score >= 7:
            severity = "éœ€è¦å…³æ³¨"
            recommendations = [
                "å»ºè®®å°½å¿«å’¨è¯¢ä¸“ä¸šå¿ƒç†å¥åº·åŒ»ç”Ÿ",
                "å¯†åˆ‡å…³æ³¨æƒ…ç»ªå’Œè¡Œä¸ºå˜åŒ–", 
                "ä¿æŒè§„å¾‹çš„ä½œæ¯æ—¶é—´"
            ]
            lifestyle = [
                "é¿å…è¿‡åº¦åˆºæ¿€å’Œå‹åŠ›",
                "ä¿æŒé€‚åº¦è¿åŠ¨",
                "å¯»æ±‚å®¶äººæœ‹å‹çš„æ”¯æŒ"
            ]
        else:
            severity = "ç›¸å¯¹ç¨³å®š"
            recommendations = [
                "ç»§ç»­å…³æ³¨å¿ƒç†å¥åº·çŠ¶å†µ",
                "å¦‚æœ‰ç—‡çŠ¶å˜åŒ–åŠæ—¶å°±è¯Š"
            ]
            lifestyle = [
                "ä¿æŒå¥åº·çš„ç”Ÿæ´»æ–¹å¼",
                "å®šæœŸè¿›è¡Œå¿ƒç†å¥åº·è¯„ä¼°"
            ]
        
        return f"""
    ã€æ‰§è¡Œæ‘˜è¦ã€‘ï¼šæ ¹æ®MDQè¯„ä¼°ç»“æœï¼ˆ{mdq_score}/13åˆ†ï¼‰ï¼Œæ‚£è€…å½“å‰çŠ¶æ€{severity}ï¼Œå»ºè®®æŒç»­å…³æ³¨å’Œä¸“ä¸šè¯„ä¼°ã€‚

    ã€ä¸´åºŠè¯„ä¼°ã€‘ï¼šMDQé—®å·æ˜¾ç¤ºæ‚£è€…å¾—åˆ†ä¸º{mdq_score}åˆ†ï¼Œé£é™©è¯„ä¼°ä¸º{risk_percentage}%ã€‚æ ¹æ®æ ‡å‡†MDQè¯„åˆ†æ ‡å‡†ï¼Œ{'å»ºè®®è¿›ä¸€æ­¥ä¸“ä¸šè¯„ä¼°' if mdq_score >= 7 else 'æš‚æ— æ˜æ˜¾å¼‚å¸¸ï¼Œä½†éœ€æŒç»­å…³æ³¨'}ã€‚

    ã€é£é™©è¯„ä¼°ã€‘ï¼š{'ä¸­ç­‰é£é™©ï¼Œéœ€è¦ä¸“ä¸šåŒ»ç”Ÿè¯„ä¼°' if mdq_score >= 7 else 'ä½é£é™©ï¼Œå»ºè®®å®šæœŸå¤æŸ¥'}ã€‚

    ã€æ²»ç–—å»ºè®®ã€‘ï¼š
    {chr(10).join(f'- {rec}' for rec in recommendations)}

    ã€ç”Ÿæ´»æ–¹å¼å»ºè®®ã€‘ï¼š
    {chr(10).join(f'- {rec}' for rec in lifestyle)}

    ã€ç›‘æµ‹è®¡åˆ’ã€‘ï¼šå»ºè®®{'æ¯æœˆ' if mdq_score >= 7 else 'æ¯å­£åº¦'}è¿›è¡Œä¸€æ¬¡å¿ƒç†å¥åº·è¯„ä¼°ï¼Œå¦‚æœ‰ç—‡çŠ¶å˜åŒ–åŠæ—¶å°±è¯Šã€‚

    ã€ç´§æ€¥é¢„æ¡ˆã€‘ï¼šå¦‚å‡ºç°ä¸¥é‡æƒ…ç»ªæ³¢åŠ¨ã€è‡ªä¼¤è‡ªæ€æƒ³æ³•æˆ–ä¸¥é‡åŠŸèƒ½æŸå®³ï¼Œè¯·ç«‹å³è”ç³»ä¸“ä¸šåŒ»ç”Ÿæˆ–æ‹¨æ‰“æ€¥æ•‘ç”µè¯ã€‚

    *æ³¨ï¼šæœ¬æŠ¥å‘Šç”±äºç½‘ç»œåŸå› é‡‡ç”¨å¤‡ç”¨ç”Ÿæˆæ¨¡å¼ï¼Œå»ºè®®åç»­å¯»æ±‚ä¸“ä¸šåŒ»ç”Ÿçš„è¯¦ç»†è¯„ä¼°ã€‚*
    """
    def generate_historical_analysis_report(self, user_id: str) -> AdvisorReport:
        """ç”Ÿæˆå†å²è¶‹åŠ¿åˆ†ææŠ¥å‘Š"""
        start_time = time.time()
        
        # è·å–ç”¨æˆ·æœ€æ–°åˆ†æ
        analysis_history = self.analyzer.get_analysis_history(user_id, limit=1)
        if not analysis_history:
            raise ValueError(f"ç”¨æˆ· {user_id} æ²¡æœ‰åˆ†æè®°å½•")
        
        latest_analysis_id = analysis_history[0]['analysis_id']
        ai_data = self.analyzer.get_ai_analysis_data(latest_analysis_id)
        
        if not ai_data:
            raise ValueError(f"ç”¨æˆ· {user_id} çš„AIæ•°æ®ä¸å®Œæ•´")
        
        # å‡†å¤‡AIè¾“å…¥æ•°æ®
        ai_input = self._prepare_historical_input(ai_data)
        
        # è°ƒç”¨DeepSeek API
        user_prompt = self.prompts['historical']['user_template'].format(**ai_input)
        ai_response = self._call_deepseek_api(
            self.prompts['historical']['system'],
            user_prompt
        )
        
        # è§£æAIå“åº”
        parsed_response = self._parse_historical_response(ai_response)
        
        # è®¡ç®—å¤„ç†æ—¶é—´
        processing_time = time.time() - start_time
        
        # åˆ›å»ºæŠ¥å‘Šå¯¹è±¡
        report = AdvisorReport(
            report_id=str(uuid.uuid4()),
            user_id=user_id,
            report_type='historical_analysis',
            analysis_id=latest_analysis_id,
            generated_at=datetime.now(),
            
            executive_summary=parsed_response['executive_summary'],
            clinical_assessment=parsed_response.get('clinical_assessment', ''),
            risk_evaluation=parsed_response.get('risk_evaluation', ''),
            treatment_recommendations=parsed_response.get('treatment_recommendations', ''),
            lifestyle_recommendations=parsed_response.get('lifestyle_recommendations', ''),
            monitoring_plan=parsed_response.get('monitoring_plan', ''),
            emergency_protocols=parsed_response.get('emergency_protocols', ''),
            
            progress_analysis=parsed_response['progress_analysis'],
            trend_interpretation=parsed_response['trend_interpretation'],
            prognosis_assessment=parsed_response['prognosis_assessment'],
            
            confidence_score=parsed_response.get('confidence_score', 0.8),
            processing_time=processing_time
        )
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        self._save_report(report, ai_input, ai_response)
        
        return report
    
    def _prepare_single_test_input(self, ai_data: Dict) -> Dict:
        """å‡†å¤‡å•æ¬¡æµ‹è¯•çš„AIè¾“å…¥æ•°æ® - ä¿®å¤ç‰ˆ"""
        try:
            # ä»ä¸åŒçš„æ•°æ®ç»“æ„ä¸­æå–ä¿¡æ¯
            demographics = ai_data.get('patient_demographics', {})
            mdq_standard = ai_data.get('mdq_standard_results', {})
            symptom_patterns = ai_data.get('symptom_patterns', {})
            clinical_context = ai_data.get('clinical_context', {})
            
            # å…¼å®¹æ—§æ•°æ®æ ¼å¼
            if not mdq_standard and 'mdq_part1_score' in ai_data:
                mdq_standard = {
                    'part1_score': ai_data.get('mdq_part1_score', 0),
                    'has_co_occurrence': ai_data.get('has_co_occurrence', False),
                    'functional_impact_level': ai_data.get('functional_impact_level', 'no_problems'),
                    'mdq_result': ai_data.get('mdq_result', 'negative'),
                    'severity_level': ai_data.get('severity_level', 'negative'),
                    'risk_percentage': ai_data.get('risk_percentage', 0)
                }
            
            if not symptom_patterns and 'positive_symptoms' in ai_data:
                symptom_patterns = {
                    'positive_symptoms_list': ai_data.get('positive_symptoms', []),
                    'core_symptoms_count': ai_data.get('core_symptoms_count', 0),
                    'symptom_profile': ai_data.get('symptom_profile', {})
                }
            
            # å®‰å…¨è·å–åŸºæœ¬ä¿¡æ¯
            age = demographics.get('age', ai_data.get('age', 'æœªçŸ¥'))
            gender = demographics.get('gender', ai_data.get('gender', 'æœªçŸ¥'))
            total_assessments = demographics.get('total_assessments', ai_data.get('total_assessments', 1))
            assessment_span = demographics.get('assessment_span_days', ai_data.get('assessment_span_days', 0))
            
            # å®‰å…¨è·å–MDQç›¸å…³ä¿¡æ¯
            mdq_score = mdq_standard.get('part1_score', ai_data.get('mdq_part1_score', 0))
            risk_percentage = mdq_standard.get('risk_percentage', ai_data.get('risk_percentage', 0))
            severity_level = mdq_standard.get('severity_level', ai_data.get('severity_level', 'negative'))
            functional_impact = mdq_standard.get('functional_impact_level', ai_data.get('functional_impact_level', 'no_problems'))
            
            # å¤„ç†ç—‡çŠ¶ä¿¡æ¯
            positive_symptoms = symptom_patterns.get('positive_symptoms_list', ai_data.get('positive_symptoms', []))
            core_symptoms_count = symptom_patterns.get('core_symptoms_count', ai_data.get('core_symptoms_count', 0))
            
            # æ ¼å¼åŒ–ç—‡çŠ¶åˆ†å¸ƒï¼ˆç®€åŒ–ç‰ˆï¼‰
            symptom_categories = symptom_patterns.get('symptom_categories', {})
            if not symptom_categories and 'symptom_profile' in ai_data:
                # ä»symptom_profileç”Ÿæˆç®€åŒ–çš„åˆ†ç±»
                profile = ai_data.get('symptom_profile', {})
                mood_symptoms = sum(1 for q in ['q1', 'q2'] if profile.get(q, False))
                cognitive_symptoms = sum(1 for q in ['q5', 'q6'] if profile.get(q, False))
                behavioral_symptoms = sum(1 for q in ['q7', 'q8', 'q9'] if profile.get(q, False))
                
                symptom_categories = {
                    'mood_elevation': {'positive_count': mood_symptoms, 'total_count': 2},
                    'cognitive_symptoms': {'positive_count': cognitive_symptoms, 'total_count': 2},
                    'behavioral_activation': {'positive_count': behavioral_symptoms, 'total_count': 3}
                }
            
            symptom_text = ""
            for category, data in symptom_categories.items():
                if isinstance(data, dict) and 'positive_count' in data:
                    symptom_text += f"- {category.replace('_', ' ').title()}: {data['positive_count']}/{data['total_count']}\n"
            
            # æ ¼å¼åŒ–é˜³æ€§ç—‡çŠ¶
            symptoms_text = "\n".join([f"- {symptom}" for symptom in positive_symptoms[:5]])  # é™åˆ¶æ˜¾ç¤ºå‰5ä¸ª
            if not symptoms_text:
                symptoms_text = "æ— æ˜æ˜¾é˜³æ€§ç—‡çŠ¶"
            
            # è·å–ä¸´åºŠä¸Šä¸‹æ–‡
            emergency_indicators = clinical_context.get('emergency_indicators', [])
            monitoring_priorities = clinical_context.get('monitoring_priorities', [])
            intervention_targets = clinical_context.get('intervention_targets', [])
            
            return {
                'age': str(age),
                'gender': str(gender),
                'total_assessments': int(total_assessments),
                'assessment_span_days': int(assessment_span),
                'mdq_score': int(mdq_score),
                'weighted_score': float(mdq_score),  # ç®€åŒ–ï¼šä½¿ç”¨MDQåˆ†æ•°
                'severity_level': str(severity_level).replace('_', ' ').title(),
                'risk_percentage': float(risk_percentage),
                'functional_impairment': str(functional_impact).replace('_', ' ').title(),
                'symptom_distribution': symptom_text if symptom_text else "æš‚æ— è¯¦ç»†ç—‡çŠ¶åˆ†å¸ƒæ•°æ®",
                'bipolar_risk_profile': f"MDQé˜³æ€§: {'æ˜¯' if mdq_score >= 7 else 'å¦'}\nç—‡çŠ¶å…±ç°: {'æ˜¯' if mdq_standard.get('has_co_occurrence', False) else 'å¦'}",
                'positive_symptoms': symptoms_text,
                'emergency_indicators': ', '.join(emergency_indicators) if emergency_indicators else 'æ— ',
                'monitoring_priorities': ', '.join(monitoring_priorities) if monitoring_priorities else 'å¸¸è§„ç›‘æµ‹',
                'intervention_targets': ', '.join(intervention_targets) if intervention_targets else 'æ— ç‰¹æ®Šå¹²é¢„ç›®æ ‡'
            }
            
        except Exception as e:
            print(f"å‡†å¤‡AIè¾“å…¥æ•°æ®å¤±è´¥: {e}")
            # è¿”å›æœ€åŸºæœ¬çš„æ•°æ®ç»“æ„
            return {
                'age': 'æœªçŸ¥',
                'gender': 'æœªçŸ¥',
                'total_assessments': 1,
                'assessment_span_days': 0,
                'mdq_score': ai_data.get('mdq_part1_score', 0),
                'weighted_score': ai_data.get('mdq_part1_score', 0),
                'severity_level': 'éœ€è¦è¯„ä¼°',
                'risk_percentage': ai_data.get('risk_percentage', 0),
                'functional_impairment': 'éœ€è¦è¯„ä¼°',
                'symptom_distribution': 'æ•°æ®å¤„ç†ä¸­å‡ºç°é”™è¯¯',
                'bipolar_risk_profile': 'éœ€è¦é‡æ–°è¯„ä¼°',
                'positive_symptoms': 'æ•°æ®è·å–å¤±è´¥',
                'emergency_indicators': 'æ— ',
                'monitoring_priorities': 'å»ºè®®ä¸“ä¸šè¯„ä¼°',
                'intervention_targets': 'éœ€è¦è¿›ä¸€æ­¥è¯„ä¼°'
            }
    
    def _prepare_historical_input(self, ai_data: Dict) -> Dict:
        """å‡†å¤‡å†å²åˆ†æçš„AIè¾“å…¥æ•°æ®"""
        demographics = ai_data.get('patient_demographics', {})
        clinical_state = ai_data.get('current_clinical_state', {})
        trajectory = ai_data.get('historical_trajectory', {})
        treatment_response = ai_data.get('treatment_response', {})
        stats = ai_data.get('statistical_features', {})
        prognosis = ai_data.get('clinical_context', {}).get('prognosis_factors', {})
        
        # æ ¼å¼åŒ–åˆ†æ•°æ—¶é—´çº¿
        score_timeline = trajectory.get('score_timeline', [])
        timeline_text = "\n".join([
            f"- {point['date'][:10]}: {point['score']}åˆ† (åç¦»åŸºçº¿: {point['baseline_deviation']:+.1f})"
            for point in score_timeline[-10:]  # æœ€è¿‘10æ¬¡è®°å½•
        ])
        
        # æ ¼å¼åŒ–æ²»ç–—æŒ‡æ ‡
        treatment_indicators = treatment_response.get('treatment_indicators', {})
        treatment_text = "\n".join([f"- {k.replace('_', ' ').title()}: {v}" for k, v in treatment_indicators.items() if v != True])
        
        # æ ¼å¼åŒ–æ¢å¤æŒ‡æ ‡
        recovery_indicators = treatment_response.get('recovery_indicators', [])
        recovery_text = "\n".join([f"- {indicator}" for indicator in recovery_indicators])
        
        # æ ¼å¼åŒ–é£é™©å› ç´ 
        risk_factors = treatment_response.get('current_risk_factors', [])
        risk_text = "\n".join([f"- {factor}" for factor in risk_factors])
        
        return {
            'age': demographics.get('age', 'æœªçŸ¥'),
            'gender': demographics.get('gender', 'æœªçŸ¥'),
            'total_assessments': demographics.get('total_assessments', 0),
            'assessment_span_days': demographics.get('assessment_span_days', 0),
            'current_score': clinical_state.get('mdq_score', 0),
            'severity_level': clinical_state.get('severity_level', 'æœªçŸ¥'),
            'risk_percentage': clinical_state.get('risk_percentage', 0),
            'improvement_trend': trajectory.get('improvement_trend', 'æœªçŸ¥'),
            'trend_confidence': round(trajectory.get('trend_confidence', 0), 2),
            'baseline_score': round(trajectory.get('baseline_score', 0), 1),
            'improvement_percentage': round(treatment_response.get('improvement_percentage', 0), 1),
            'consistency_score': round(treatment_response.get('consistency_score', 0), 2),
            'score_timeline': timeline_text if timeline_text else 'æš‚æ— å……è¶³å†å²æ•°æ®',
            'treatment_indicators': treatment_text if treatment_text else 'æš‚æ— æ²»ç–—ååº”æ•°æ®',
            'recovery_indicators': recovery_text if recovery_text else 'æš‚æ— æ˜æ˜¾æ¢å¤æŒ‡æ ‡',
            'current_risk_factors': risk_text if risk_text else 'æš‚æ— æ˜æ˜¾é£é™©å› ç´ ',
            'positive_factors': ', '.join(prognosis.get('positive_factors', [])) if prognosis.get('positive_factors') else 'æš‚æ— ',
            'negative_factors': ', '.join(prognosis.get('negative_factors', [])) if prognosis.get('negative_factors') else 'æš‚æ— ',
            'score_mean': round(stats.get('score_mean', 0), 1),
            'score_std': round(stats.get('score_std', 0), 1),
            'score_range': stats.get('score_range', 0),
            'variability_coefficient': round(stats.get('variability_coefficient', 0), 2)
        }
    
    def _call_deepseek_api(self, system_prompt: str, user_prompt: str) -> str:
        """è°ƒç”¨DeepSeek API - å¢å¼ºé”™è¯¯å¤„ç†"""
        try:
            # æ·»åŠ è¶…æ—¶å’Œé‡è¯•æœºåˆ¶
            import time
            max_retries = 3
            
            for attempt in range(max_retries):
                try:
                    response = self.client.chat.completions.create(
                        model="deepseek-chat",
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        max_tokens=4000,
                        temperature=0.7,
                        stream=False,
                        timeout=30  # 30ç§’è¶…æ—¶
                    )
                    
                    return response.choices[0].message.content
                    
                except Exception as e:
                    print(f"DeepSeek APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                    if attempt < max_retries - 1:
                        time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                    else:
                        raise e
                        
        except Exception as e:
            raise Exception(f"DeepSeek APIè°ƒç”¨æœ€ç»ˆå¤±è´¥: {e}")
    
    def _parse_single_test_response(self, ai_response: str) -> Dict:
        """è§£æå•æ¬¡æµ‹è¯•AIå“åº”"""
        sections = {
            'executive_summary': '',
            'clinical_assessment': '',
            'risk_evaluation': '',
            'treatment_recommendations': [],
            'lifestyle_recommendations': [],
            'monitoring_plan': '',
            'emergency_protocols': '',
            'confidence_score': 0.8
        }
        
        # æŒ‰ç« èŠ‚åˆ†å‰²å“åº”
        section_patterns = {
            'ã€æ‰§è¡Œæ‘˜è¦ã€‘': 'executive_summary',
            'ã€ä¸´åºŠè¯„ä¼°ã€‘': 'clinical_assessment',
            'ã€é£é™©è¯„ä¼°ã€‘': 'risk_evaluation',
            'ã€æ²»ç–—å»ºè®®ã€‘': 'treatment_recommendations',
            'ã€ç”Ÿæ´»æ–¹å¼å»ºè®®ã€‘': 'lifestyle_recommendations',
            'ã€ç›‘æµ‹è®¡åˆ’ã€‘': 'monitoring_plan',
            'ã€ç´§æ€¥é¢„æ¡ˆã€‘': 'emergency_protocols'
        }
        
        current_section = None
        lines = ai_response.split('\n')
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°çš„ç« èŠ‚
            section_found = False
            for pattern, section_name in section_patterns.items():
                if pattern in line:
                    current_section = section_name
                    section_found = True
                    # æå–ç« èŠ‚æ ‡é¢˜åçš„å†…å®¹
                    content = line.replace(pattern, '').strip('ï¼š: ')
                    if content:
                        if section_name in ['treatment_recommendations', 'lifestyle_recommendations']:
                            if content.startswith('-'):
                                sections[section_name].append(content[1:].strip())
                            else:
                                sections[section_name].append(content)
                        else:
                            sections[section_name] = content
                    break
            
            if not section_found and current_section:
                # ç»§ç»­å½“å‰ç« èŠ‚çš„å†…å®¹
                if current_section in ['treatment_recommendations', 'lifestyle_recommendations']:
                    if line.startswith('-'):
                        sections[current_section].append(line[1:].strip())
                    elif line.startswith(('â€¢', '*', '1.', '2.', '3.', '4.', '5.')):
                        clean_line = line.lstrip('â€¢*123456789. ')
                        sections[current_section].append(clean_line)
                    elif sections[current_section] and not any(x in line for x in ['ã€', 'ã€‘']):
                        # å¦‚æœä¸æ˜¯æ–°ç« èŠ‚ä¸”æœ‰å†…å®¹ï¼Œè¿½åŠ åˆ°æœ€åä¸€ä¸ªå»ºè®®
                        sections[current_section][-1] += ' ' + line
                else:
                    if sections[current_section]:
                        sections[current_section] += ' ' + line
                    else:
                        sections[current_section] = line
        
        # ç¡®ä¿å¿…è¦å­—æ®µä¸ä¸ºç©º
        if not sections['executive_summary']:
            sections['executive_summary'] = 'æ‚£è€…éœ€è¦ä¸“ä¸šåŒ»ç”Ÿè¿›ä¸€æ­¥è¯„ä¼°'
        if not sections['clinical_assessment']:
            sections['clinical_assessment'] = 'å»ºè®®è¿›è¡Œå…¨é¢çš„ä¸´åºŠè¯„ä¼°'
        if not sections['risk_evaluation']:
            sections['risk_evaluation'] = 'é£é™©è¯„ä¼°éœ€è¦ä¸“ä¸šåŒ»ç”Ÿåˆ¤æ–­'
        if not sections['treatment_recommendations']:
            sections['treatment_recommendations'] = ['å’¨è¯¢ç²¾ç¥ç§‘åŒ»ç”Ÿåˆ¶å®šä¸ªæ€§åŒ–æ²»ç–—æ–¹æ¡ˆ']
        if not sections['lifestyle_recommendations']:
            sections['lifestyle_recommendations'] = ['ä¿æŒè§„å¾‹ä½œæ¯å’Œå¥åº·ç”Ÿæ´»æ–¹å¼']
        if not sections['monitoring_plan']:
            sections['monitoring_plan'] = 'å»ºè®®å®šæœŸéšè®¿å’Œç—‡çŠ¶ç›‘æµ‹'
        if not sections['emergency_protocols']:
            sections['emergency_protocols'] = 'å¦‚æœ‰ç´§æ€¥æƒ…å†µï¼Œè¯·ç«‹å³è”ç³»åŒ»ç”Ÿæˆ–æ‹¨æ‰“æ€¥æ•‘ç”µè¯'
        
        return sections
    
    def _parse_historical_response(self, ai_response: str) -> Dict:
        """è§£æå†å²åˆ†æAIå“åº”"""
        # å®šä¹‰5ä¸ªéƒ¨åˆ†çš„è§£ææ¨¡å¼
        historical_patterns = {
            'ã€æ‰§è¡Œæ‘˜è¦ã€‘': 'executive_summary',
            'ã€è¿›å±•åˆ†æã€‘': 'progress_analysis',
            'ã€è¶‹åŠ¿è§£è¯»ã€‘': 'trend_interpretation',
            'ã€æ²»ç–—å»ºè®®ã€‘': 'treatment_recommendations',
            'ã€é¢„åè¯„ä¼°ã€‘': 'prognosis_assessment'
        }
        
        # åˆå§‹åŒ–æ‰€æœ‰å­—æ®µ
        sections = {
            'executive_summary': '',
            'progress_analysis': '',
            'trend_interpretation': '',
            'treatment_recommendations': '',
            'prognosis_assessment': ''
        }
        
        current_section = None
        lines = ai_response.split('\n')
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # æ£€æŸ¥å†å²åˆ†æç« èŠ‚
            for pattern, section_name in historical_patterns.items():
                if pattern in line:
                    current_section = section_name
                    content = line.replace(pattern, '').strip('ï¼š: ')
                    if content:
                        sections[section_name] = content
                    break
            else:
                # ç»§ç»­å½“å‰å†å²åˆ†æç« èŠ‚çš„å†…å®¹
                if current_section and current_section in historical_patterns.values():
                    if sections[current_section]:
                        sections[current_section] += ' ' + line
                    else:
                        sections[current_section] = line
        
        # ä¸ºç©ºçš„å†å²åˆ†æå­—æ®µæä¾›é»˜è®¤å€¼
        if not sections['executive_summary']:
            sections['executive_summary'] = 'åŸºäºå†å²æ•°æ®åˆ†æï¼Œæ‚£è€…æ•´ä½“æ²»ç–—è¿›å±•éœ€è¦æŒç»­ç›‘æµ‹å’Œä¸“ä¸šè¯„ä¼°'
        if not sections['progress_analysis']:
            sections['progress_analysis'] = 'åŸºäºç°æœ‰æ•°æ®æ˜¾ç¤ºæ‚£è€…æ²»ç–—è¿›å±•éœ€è¦æŒç»­ç›‘æµ‹å’Œä¸“ä¸šè¯„ä¼°'
        if not sections['trend_interpretation']:
            sections['trend_interpretation'] = 'ç—‡çŠ¶è¶‹åŠ¿å˜åŒ–éœ€è¦ç»“åˆä¸´åºŠè¡¨ç°è¿›è¡Œç»¼åˆåˆ¤æ–­'
        if not sections['treatment_recommendations']:
            sections['treatment_recommendations'] = 'å»ºè®®ç»§ç»­å½“å‰æ²»ç–—æ–¹æ¡ˆï¼Œå®šæœŸè¯„ä¼°æ•ˆæœ'
        if not sections['prognosis_assessment']:
            sections['prognosis_assessment'] = 'é¢„åè¯„ä¼°éœ€è¦è€ƒè™‘å¤šä¸ªå› ç´ ï¼Œå»ºè®®å®šæœŸä¸“ä¸šè¯„ä¼°'
        
        return sections
    
    def _save_report(self, report: AdvisorReport, ai_input: Dict, ai_response: str) -> bool:
        """ä¿å­˜æŠ¥å‘Šåˆ°æ•°æ®åº“"""
        try:
            conn = self.db_manager._get_connection()
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO ai_advisor_reports (
                    report_id, user_id, report_type, analysis_id, generated_at,
                    executive_summary, clinical_assessment, risk_evaluation,
                    treatment_recommendations, lifestyle_recommendations,
                    monitoring_plan, emergency_protocols,
                    progress_analysis, trend_interpretation, prognosis_assessment,
                    confidence_score, ai_model_version, processing_time,
                    ai_input_data, ai_response_raw
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                report.report_id,
                report.user_id,
                report.report_type,
                report.analysis_id,
                report.generated_at.isoformat(),
                report.executive_summary,
                getattr(report, 'clinical_assessment', ''),
                getattr(report, 'risk_evaluation', ''),
                json.dumps(getattr(report, 'treatment_recommendations', ''), ensure_ascii=False),
                json.dumps(getattr(report, 'lifestyle_recommendations', ''), ensure_ascii=False),
                getattr(report, 'monitoring_plan', ''),
                getattr(report, 'emergency_protocols', ''),
                report.progress_analysis,
                report.trend_interpretation,
                report.prognosis_assessment,
                report.confidence_score,
                report.ai_model_version,
                report.processing_time,
                json.dumps(ai_input, ensure_ascii=False),
                ai_response
            ))
            
            conn.commit()
            print(f"AIé¡¾é—®æŠ¥å‘Šå·²ä¿å­˜: {report.report_id}")
            return True
            
        except sqlite3.Error as e:
            print(f"ä¿å­˜AIé¡¾é—®æŠ¥å‘Šå¤±è´¥: {e}")
            return False
        finally:
            if conn:
                conn.close()
    
    def get_report(self, report_id: str) -> Optional[Dict]:
        """è·å–æŠ¥å‘Šè¯¦æƒ…"""
        try:
            conn = self.db_manager._get_connection()
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT * FROM ai_advisor_reports WHERE report_id = ?
            ''', (report_id,))
            
            result = cursor.fetchone()
            
            if result:
                columns = [description[0] for description in cursor.description]
                report_data = dict(zip(columns, result))
                
                # è§£æJSONå­—æ®µ
                json_fields = ['treatment_recommendations', 'lifestyle_recommendations', 
                             'ai_input_data']
                
                for field in json_fields:
                    if report_data[field]:
                        try:
                            report_data[field] = json.loads(report_data[field])
                        except json.JSONDecodeError:
                            pass
                
                return report_data
            
            return None
            
        except sqlite3.Error as e:
            print(f"è·å–AIæŠ¥å‘Šå¤±è´¥: {e}")
            return None
        finally:
            if conn:
                conn.close()
    
    def get_user_reports(self, user_id: str, report_type: Optional[str] = None, limit: int = 10) -> List[Dict]:
        """è·å–ç”¨æˆ·çš„æŠ¥å‘Šå†å²"""
        try:
            conn = self.db_manager._get_connection()
            cursor = conn.cursor()
            
            query = '''
                SELECT report_id, report_type, generated_at, confidence_score, processing_time
                FROM ai_advisor_reports
                WHERE user_id = ?
            '''
            params = [user_id]
            
            if report_type:
                query += ' AND report_type = ?'
                params.append(report_type)
            
            query += ' ORDER BY generated_at DESC LIMIT ?'
            params.append(limit)
            
            cursor.execute(query, params)
            results = cursor.fetchall()
            
            return [{
                'report_id': row[0],
                'report_type': row[1],
                'generated_at': row[2],
                'confidence_score': row[3],
                'processing_time': row[4]
            } for row in results]
            
        except sqlite3.Error as e:
            print(f"è·å–ç”¨æˆ·æŠ¥å‘Šå†å²å¤±è´¥: {e}")
            return []
        finally:
            if conn:
                conn.close()

# ä¾¿æ·åŠŸèƒ½å‡½æ•°
def generate_quick_report(user_id: str, report_type: str = 'both') -> Dict:
    """å¿«é€Ÿç”ŸæˆæŠ¥å‘Šçš„ä¾¿æ·å‡½æ•°"""
    db_manager = DatabaseManager()
    analyzer = MDQAnalyzer(db_manager)
    advisor = DeepSeekAdvisor(db_manager, analyzer)
    
    results = {}
    
    try:
        if report_type in ['single', 'both']:
            # è·å–æœ€æ–°åˆ†æID
            analysis_history = analyzer.get_analysis_history(user_id, limit=1)
            if analysis_history:
                analysis_id = analysis_history[0]['analysis_id']
                single_report = advisor.generate_single_test_report(analysis_id)
                results['single_test_report'] = {
                    'report_id': single_report.report_id,
                    'executive_summary': single_report.executive_summary,
                    'treatment_recommendations': single_report.treatment_recommendations,
                    'emergency_protocols': single_report.emergency_protocols
                }
        
        if report_type in ['historical', 'both']:
            historical_report = advisor.generate_historical_analysis_report(user_id)
            results['historical_report'] = {
                'report_id': historical_report.report_id,
                'progress_analysis': historical_report.progress_analysis,
                'trend_interpretation': historical_report.trend_interpretation,
                'prognosis_assessment': historical_report.prognosis_assessment
            }
        
        return {'success': True, 'reports': results}
        
    except Exception as e:
        return {'success': False, 'error': str(e)}

def batch_generate_reports(report_type: str = 'both') -> Dict:
    """æ‰¹é‡ä¸ºæ‰€æœ‰ç”¨æˆ·ç”ŸæˆæŠ¥å‘Š"""
    db_manager = DatabaseManager()
    analyzer = MDQAnalyzer(db_manager)
    advisor = DeepSeekAdvisor(db_manager, analyzer)
    
    try:
        conn = db_manager._get_connection()
        cursor = conn.cursor()
        
        # è·å–æ‰€æœ‰æœ‰åˆ†æè®°å½•çš„ç”¨æˆ·
        cursor.execute('''
            SELECT DISTINCT user_id FROM mdq_analysis_results
        ''')
        
        user_ids = [row[0] for row in cursor.fetchall()]
        
        results = {
            'total_users': len(user_ids),
            'successful_reports': 0,
            'failed_reports': 0,
            'reports': {}
        }
        
        for user_id in user_ids:
            try:
                user_results = generate_quick_report(user_id, report_type)
                if user_results['success']:
                    results['successful_reports'] += 1
                    results['reports'][user_id] = user_results['reports']
                else:
                    results['failed_reports'] += 1
                    print(f"ç”¨æˆ· {user_id[:8]} æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {user_results['error']}")
                    
            except Exception as e:
                results['failed_reports'] += 1
                print(f"ç”¨æˆ· {user_id[:8]} æŠ¥å‘Šç”Ÿæˆå‡ºé”™: {e}")
        
        return results
        
    except Exception as e:
        return {'success': False, 'error': str(e)}
        
    finally:
        if conn:
            conn.close()

# æŠ¥å‘Šæ ¼å¼åŒ–å’Œå¯¼å‡ºåŠŸèƒ½
def format_report_for_display(report_data: Dict) -> str:
    """æ ¼å¼åŒ–æŠ¥å‘Šç”¨äºæ˜¾ç¤º"""
    if not report_data:
        return "æŠ¥å‘Šä¸å­˜åœ¨"
    
    report_type_names = {
        'single_test': 'å•æ¬¡æµ‹è¯•åˆ†ææŠ¥å‘Š',
        'historical_analysis': 'å†å²è¶‹åŠ¿åˆ†ææŠ¥å‘Š'
    }
    
    formatted_text = f"""
# {report_type_names.get(report_data['report_type'], 'åˆ†ææŠ¥å‘Š')}

**æŠ¥å‘ŠID:** {report_data['report_id']}
**ç”Ÿæˆæ—¶é—´:** {report_data['generated_at'][:19]}
**AIæ¨¡å‹:** {report_data['ai_model_version']}
**ç½®ä¿¡åº¦:** {report_data['confidence_score']:.2f}
**å¤„ç†æ—¶é—´:** {report_data['processing_time']:.2f}ç§’

---

## ğŸ“‹ æ‰§è¡Œæ‘˜è¦
{report_data['executive_summary']}

## ğŸ¥ ä¸´åºŠè¯„ä¼°
{report_data['clinical_assessment']}

## âš ï¸ é£é™©è¯„ä¼°
{report_data['risk_evaluation']}

## ğŸ’Š æ²»ç–—å»ºè®®
"""
    
    # å¤„ç†æ²»ç–—å»ºè®®
    treatment_recs = report_data['treatment_recommendations']
    if isinstance(treatment_recs, list):
        for i, rec in enumerate(treatment_recs, 1):
            formatted_text += f"{i}. {rec}\n"
    else:
        formatted_text += f"{treatment_recs}\n"
    
    formatted_text += "\n## ğŸ’¡ ç”Ÿæ´»æ–¹å¼å»ºè®®\n"
    
    # å¤„ç†ç”Ÿæ´»æ–¹å¼å»ºè®®
    lifestyle_recs = report_data['lifestyle_recommendations']
    if isinstance(lifestyle_recs, list):
        for i, rec in enumerate(lifestyle_recs, 1):
            formatted_text += f"{i}. {rec}\n"
    else:
        formatted_text += f"{lifestyle_recs}\n"
    
    formatted_text += f"""
## ğŸ“… ç›‘æµ‹è®¡åˆ’
{report_data['monitoring_plan']}

## ğŸš¨ ç´§æ€¥é¢„æ¡ˆ
{report_data['emergency_protocols']}
"""
    
    # å¦‚æœæ˜¯å†å²åˆ†ææŠ¥å‘Šï¼Œæ·»åŠ é¢å¤–å†…å®¹
    if report_data['report_type'] == 'historical_analysis':
        formatted_text += f"""
---

## ğŸ“ˆ è¿›å±•åˆ†æ
{report_data['progress_analysis']}

## ğŸ“Š è¶‹åŠ¿è§£è¯»
{report_data['trend_interpretation']}

## ğŸ”® é¢„åè¯„ä¼°
{report_data['prognosis_assessment']}
"""
    
    return formatted_text

def export_report_to_file(report_id: str, filename: Optional[str] = None) -> str:
    """å¯¼å‡ºæŠ¥å‘Šåˆ°æ–‡ä»¶"""
    db_manager = DatabaseManager()
    analyzer = MDQAnalyzer(db_manager)
    advisor = DeepSeekAdvisor(db_manager, analyzer)
    
    report = advisor.get_report(report_id)
    if not report:
        return "æŠ¥å‘Šä¸å­˜åœ¨"
    
    if filename is None:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"mdq_report_{report_id[:8]}_{timestamp}.txt"
    
    formatted_text = format_report_for_display(report)
    
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(formatted_text)
        return f"æŠ¥å‘Šå·²å¯¼å‡ºåˆ°: {filename}"
    except Exception as e:
        return f"å¯¼å‡ºå¤±è´¥: {e}"

# æµ‹è¯•å‡½æ•°
def test_deepseek_advisor():
    """æµ‹è¯•DeepSeek AIé¡¾é—®åŠŸèƒ½"""
    print("=== DeepSeek AI é¡¾é—®ç³»ç»Ÿæµ‹è¯• ===")
    
    # æ£€æŸ¥APIå¯†é’¥è®¾ç½®
    if DEEPSEEK_API_KEY == "your_deepseek_api_key_here":
        print("âŒ è¯·å…ˆåœ¨æ–‡ä»¶é¡¶éƒ¨è®¾ç½®æœ‰æ•ˆçš„ DeepSeek API å¯†é’¥")
        print("è¯·ä¿®æ”¹æ–‡ä»¶é¡¶éƒ¨çš„ DEEPSEEK_API_KEY å˜é‡")
        print("è·å–APIå¯†é’¥: https://platform.deepseek.com/")
        return
    
    # åˆå§‹åŒ–ç»„ä»¶
    try:
        db_manager = DatabaseManager()
        analyzer = MDQAnalyzer(db_manager)
        advisor = DeepSeekAdvisor(db_manager, analyzer)
        print("âœ… AIé¡¾é—®ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # æŸ¥æ‰¾ç°æœ‰ç”¨æˆ·è¿›è¡Œæµ‹è¯•
    try:
        conn = db_manager._get_connection()
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT DISTINCT ar.user_id, ar.analysis_id, u.username
            FROM mdq_analysis_results ar
            JOIN users u ON ar.user_id = u.user_id
            ORDER BY ar.analysis_date DESC
            LIMIT 1
        ''')
        
        result = cursor.fetchone()
        
        if not result:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°åˆ†æç»“æœï¼Œè¯·å…ˆè¿è¡Œ analyse.py ç”Ÿæˆåˆ†ææ•°æ®")
            return
        
        user_id, analysis_id, username = result
        print(f"æµ‹è¯•ç”¨æˆ·: {username} (ID: {user_id[:8]}...)")
        print(f"åˆ†æID: {analysis_id[:8]}...")
        
        # æµ‹è¯•1: ç”Ÿæˆå•æ¬¡åˆ†ææŠ¥å‘Š
        print(f"\n=== æµ‹è¯•1: ç”Ÿæˆå•æ¬¡æµ‹è¯•åˆ†ææŠ¥å‘Š ===")
        try:
            print("æ­£åœ¨è°ƒç”¨DeepSeek APIç”ŸæˆæŠ¥å‘Š...")
            single_report = advisor.generate_single_test_report(analysis_id)
            
            print("âœ… å•æ¬¡åˆ†ææŠ¥å‘Šç”ŸæˆæˆåŠŸ!")
            print(f"æŠ¥å‘ŠID: {single_report.report_id}")
            print(f"å¤„ç†æ—¶é—´: {single_report.processing_time:.2f}ç§’")
            print(f"ç½®ä¿¡åº¦: {single_report.confidence_score:.2f}")
            
            print(f"\nğŸ“‹ æ‰§è¡Œæ‘˜è¦:")
            print(f"{single_report.executive_summary}")
            
            print(f"\nğŸ¥ æ²»ç–—å»ºè®®:")
            for i, rec in enumerate(single_report.treatment_recommendations[:3], 1):
                print(f"  {i}. {rec}")
            
            print(f"\nğŸ’¡ ç”Ÿæ´»æ–¹å¼å»ºè®®:")
            for i, rec in enumerate(single_report.lifestyle_recommendations[:3], 1):
                print(f"  {i}. {rec}")
                
        except Exception as e:
            print(f"âŒ å•æ¬¡åˆ†ææŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            print("è¯·æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®ï¼Œä»¥åŠç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        
        # æµ‹è¯•2: ç”Ÿæˆå†å²åˆ†ææŠ¥å‘Š
        print(f"\n=== æµ‹è¯•2: ç”Ÿæˆå†å²è¶‹åŠ¿åˆ†ææŠ¥å‘Š ===")
        try:
            print("æ­£åœ¨è°ƒç”¨DeepSeek APIç”Ÿæˆå†å²åˆ†ææŠ¥å‘Š...")
            historical_report = advisor.generate_historical_analysis_report(user_id)
            
            print("âœ… å†å²åˆ†ææŠ¥å‘Šç”ŸæˆæˆåŠŸ!")
            print(f"æŠ¥å‘ŠID: {historical_report.report_id}")
            print(f"å¤„ç†æ—¶é—´: {historical_report.processing_time:.2f}ç§’")
            print(f"ç½®ä¿¡åº¦: {historical_report.confidence_score:.2f}")
            
            print(f"\nğŸ“ˆ è¿›å±•åˆ†æ:")
            print(f"{historical_report.progress_analysis[:200]}...")
            
            print(f"\nğŸ“Š è¶‹åŠ¿è§£è¯»:")
            print(f"{historical_report.trend_interpretation[:200]}...")
            
            print(f"\nğŸ”® é¢„åè¯„ä¼°:")
            print(f"{historical_report.prognosis_assessment[:200]}...")
            
        except Exception as e:
            print(f"âŒ å†å²åˆ†ææŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
        
        # æµ‹è¯•3: æŠ¥å‘Šè·å–åŠŸèƒ½
        print(f"\n=== æµ‹è¯•3: æŠ¥å‘Šè·å–åŠŸèƒ½ ===")
        user_reports = advisor.get_user_reports(user_id)
        print(f"ç”¨æˆ·æŠ¥å‘Šå†å²: {len(user_reports)} ä¸ª")
        
        for report in user_reports:
            print(f"  - {report['report_type']}: {report['generated_at'][:19]} "
                  f"(ç½®ä¿¡åº¦: {report['confidence_score']:.2f}, "
                  f"å¤„ç†æ—¶é—´: {report['processing_time']:.2f}s)")
        
        # æµ‹è¯•4: æŠ¥å‘Šæ ¼å¼åŒ–
        if user_reports:
            print(f"\n=== æµ‹è¯•4: æŠ¥å‘Šæ ¼å¼åŒ– ===")
            latest_report_id = user_reports[0]['report_id']
            report_detail = advisor.get_report(latest_report_id)
            
            if report_detail:
                formatted_report = format_report_for_display(report_detail)
                print("âœ… æŠ¥å‘Šæ ¼å¼åŒ–æˆåŠŸ")
                print(f"æ ¼å¼åŒ–æŠ¥å‘Šé•¿åº¦: {len(formatted_report)} å­—ç¬¦")
                
                # æ˜¾ç¤ºæŠ¥å‘Šæ‘˜è¦
                lines = formatted_report.split('\n')
                for line in lines[:15]:  # æ˜¾ç¤ºå‰15è¡Œ
                    print(line)
                print("...")
            else:
                print("âŒ è·å–æŠ¥å‘Šè¯¦æƒ…å¤±è´¥")
        
        print(f"\nğŸ‰ AIé¡¾é—®ç³»ç»Ÿæµ‹è¯•å®Œæˆ!")
        print("âœ… å•æ¬¡æµ‹è¯•æŠ¥å‘Šç”ŸæˆåŠŸèƒ½æ­£å¸¸")
        print("âœ… å†å²åˆ†ææŠ¥å‘Šç”ŸæˆåŠŸèƒ½æ­£å¸¸") 
        print("âœ… æ•°æ®åº“ä¿å­˜åŠŸèƒ½æ­£å¸¸")
        print("âœ… æŠ¥å‘Šè·å–åŠŸèƒ½æ­£å¸¸")
        print("âœ… æŠ¥å‘Šæ ¼å¼åŒ–åŠŸèƒ½æ­£å¸¸")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        if conn:
            conn.close()

# å¿«é€Ÿæ¼”ç¤ºå‡½æ•°
def demo_advisor_workflow(user_id: str = None):
    """æ¼”ç¤ºAIé¡¾é—®å®Œæ•´å·¥ä½œæµç¨‹"""
    print("=== AIé¡¾é—®å·¥ä½œæµç¨‹æ¼”ç¤º ===")
    
    if DEEPSEEK_API_KEY == "your_deepseek_api_key_here":
        print("âŒ è¯·å…ˆè®¾ç½®APIå¯†é’¥")
        return
    
    db_manager = DatabaseManager()
    analyzer = MDQAnalyzer(db_manager)
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šç”¨æˆ·ï¼Œè‡ªåŠ¨é€‰æ‹©
    if not user_id:
        try:
            conn = db_manager._get_connection()
            cursor = conn.cursor()
            cursor.execute('SELECT DISTINCT user_id FROM mdq_analysis_results LIMIT 1')
            result = cursor.fetchone()
            if result:
                user_id = result[0]
            else:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°ç”¨æˆ·æ•°æ®")
                return
        finally:
            if conn:
                conn.close()
    
    try:
        advisor = DeepSeekAdvisor(db_manager, analyzer)
        
        print(f"ç”¨æˆ·ID: {user_id[:8]}...")
        
        # ç”Ÿæˆä¸¤ç§ç±»å‹çš„æŠ¥å‘Š
        print("\n1. ç”Ÿæˆå•æ¬¡æµ‹è¯•æŠ¥å‘Š...")
        single_result = generate_quick_report(user_id, 'single')
        
        print("2. ç”Ÿæˆå†å²åˆ†ææŠ¥å‘Š...")
        historical_result = generate_quick_report(user_id, 'historical')
        
        # æ˜¾ç¤ºç»“æœæ‘˜è¦
        if single_result['success']:
            single_id = single_result['reports']['single_test_report']['report_id']
            print(f"âœ… å•æ¬¡æŠ¥å‘Šç”Ÿæˆ: {single_id[:8]}...")
        
        if historical_result['success']:
            historical_id = historical_result['reports']['historical_report']['report_id'] 
            print(f"âœ… å†å²æŠ¥å‘Šç”Ÿæˆ: {historical_id[:8]}...")
        
        print("\nğŸ“Š å·¥ä½œæµç¨‹æ¼”ç¤ºå®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")

if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    test_deepseek_advisor()
    
    # å¯ä»¥å–æ¶ˆæ³¨é‡Šä¸‹é¢çš„è¡Œæ¥è¿è¡Œå…¶ä»–åŠŸèƒ½
    # demo_advisor_workflow()  # æ¼”ç¤ºå®Œæ•´å·¥ä½œæµç¨‹
    # batch_generate_reports('both')  # æ‰¹é‡ç”Ÿæˆæ‰€æœ‰ç”¨æˆ·æŠ¥å‘Š