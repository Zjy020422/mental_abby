# ====== DeepSeek API é…ç½® ======
# ä¼˜å…ˆä»ç¯å¢ƒå˜é‡è¯»å– API å¯†é’¥ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
import os

DEEPSEEK_API_KEY = os.environ.get('DEEPSEEK_API_KEY', "sk-cb387c428d9343328cea734e6ae0f9f5")

# ====== å¯¼å…¥ä¾èµ– ======
# Please install OpenAI SDK first: `pip3 install openai`
from openai import OpenAI
import json
import sqlite3
from datetime import datetime
from typing import Dict, List, Optional
from dataclasses import dataclass
import uuid
import time
from database import DatabaseManager
from analyse import MDQAnalyzer

@dataclass
class AdvisorReport:
    """AIé¡¾é—®æŠ¥å‘Šæ•°æ®ç±»"""
    report_id: str
    user_id: str
    report_type: str  # 'single_test' æˆ– 'historical_analysis'
    analysis_id: Optional[str]  # å•æ¬¡åˆ†æIDï¼ˆå•æµ‹è¯•æŠ¥å‘Šï¼‰
    generated_at: datetime
    
    # AIç”Ÿæˆçš„æŠ¥å‘Šå†…å®¹
    executive_summary: str
    clinical_assessment: Optional[str] = None
    risk_evaluation: Optional[str] = None
    treatment_recommendations: Optional[str] = None
    lifestyle_recommendations: Optional[str] = None
    monitoring_plan: Optional[str] = None
    emergency_protocols: Optional[str] = None
    
    # åŸºäºå†å²çš„å†…å®¹ï¼ˆå†å²åˆ†ææŠ¥å‘Šï¼‰
    progress_analysis: Optional[str] = None
    trend_interpretation: Optional[str] = None
    prognosis_assessment: Optional[str] = None
    
    # å…ƒæ•°æ®
    confidence_score: float = 0.0
    ai_model_version: str = "deepseek-chat"
    processing_time: float = 0.0

class DeepSeekAdvisor:
    """DeepSeek AI åˆ†æé¡¾é—®"""
    
    def __init__(self, db_manager: DatabaseManager, analyzer: MDQAnalyzer):
        self.db_manager = db_manager
        self.analyzer = analyzer
        self.client = None
        self.api_available = False

        # éªŒè¯APIå¯†é’¥å¹¶åˆå§‹åŒ–å®¢æˆ·ç«¯
        try:
            if not DEEPSEEK_API_KEY or DEEPSEEK_API_KEY == "your_deepseek_api_key_here":
                print("âš ï¸ DeepSeek API å¯†é’¥æœªè®¾ç½®ï¼Œå°†ä½¿ç”¨å¤‡ç”¨æŠ¥å‘Šç”Ÿæˆæ¨¡å¼")
                self.api_available = False
            else:
                # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
                self.client = OpenAI(
                    api_key=DEEPSEEK_API_KEY,
                    base_url="https://api.deepseek.com"
                )
                self.api_available = True
                print("âœ… DeepSeek API å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ DeepSeek API åˆå§‹åŒ–å¤±è´¥: {e}")
            print("âš ï¸ å°†ä½¿ç”¨å¤‡ç”¨æŠ¥å‘Šç”Ÿæˆæ¨¡å¼")
            self.api_available = False

        self._init_database_tables()
        
        # AI Prompt Templates
        self.prompts = {
            'single_test': {
                'system': """You are an experienced psychiatrist and bipolar disorder specialist. Based on the patient's MDQ questionnaire analysis results, generate a professional clinical assessment report and treatment recommendations.

Please provide analysis in the following 7 sections with a professional, objective, and caring tone (strictly follow this format):

[EXECUTIVE SUMMARY]: Briefly summarize the patient's current status (2-3 sentences)
[CLINICAL ASSESSMENT]: Detailed analysis of symptom presentation and severity
[RISK EVALUATION]: Assessment of current risks and potential dangers
[TREATMENT RECOMMENDATIONS]: Specific medical intervention recommendations (each recommendation on a separate line, starting with "-")
[LIFESTYLE RECOMMENDATIONS]: Daily management and self-care (each recommendation on a separate line, starting with "-")
[MONITORING PLAN]: Follow-up tracking and assessment plan
[EMERGENCY PROTOCOLS]: Crisis management procedures

Ensure all recommendations are evidence-based and follow clinical practice guidelines.""",

                'user_template': """Please generate an MDQ analysis report for the following patient:

**Patient Demographics:**
- Age: {age} years
- Gender: {gender}
- Total Assessments: {total_assessments}
- Assessment Time Span: {assessment_span_days} days

**Current Clinical Status:**
- MDQ Score: {mdq_score}/13
- Weighted Score: {weighted_score}
- Severity Level: {severity_level}
- Risk Percentage: {risk_percentage}%
- Functional Impairment: {functional_impairment}

**Symptom Distribution:**
{symptom_distribution}

**Bipolar Risk Profile:**
{bipolar_risk_profile}

**Positive Symptoms:**
{positive_symptoms}

**Emergency Indicators:** {emergency_indicators}

**Monitoring Priorities:** {monitoring_priorities}

**Intervention Targets:** {intervention_targets}

Please generate a complete clinical assessment report and treatment recommendations."""
            },
            
            'historical': {
                'system': """You are a psychiatrist specializing in long-term treatment and management of bipolar disorder. Based on the patient's historical MDQ assessment data, analyze treatment progress and prognosis, and provide comprehensive long-term treatment recommendations.

Please provide analysis in the following 5 sections (strictly follow this format):

[EXECUTIVE SUMMARY]: Brief overview of overall treatment progress and current status (2-3 sentences)
[PROGRESS ANALYSIS]: Analysis of treatment effectiveness and symptom trajectory, including improvement trends and consistency assessment
[TREND INTERPRETATION]: Professional interpretation and prediction of symptom trends based on historical data patterns
[TREATMENT RECOMMENDATIONS]: Specific medical interventions and lifestyle recommendations based on historical analysis (each recommendation on a separate line, starting with "-")
[PROGNOSIS ASSESSMENT]: Long-term prognosis and recovery potential assessment, including risk factors and protective factors

Provide recommendations based on evidence-based medicine and long-term management best practices.""",

                'user_template': """Please generate a historical trend analysis report for the following patient:

**Patient Demographics:**
- Age: {age} years
- Gender: {gender}
- Total Assessments: {total_assessments}
- Time Span: {assessment_span_days} days

**Current Status:**
- Current MDQ Score: {current_score}/13
- Severity Level: {severity_level}
- Risk Percentage: {risk_percentage}%

**Historical Trajectory:**
- Improvement Trend: {improvement_trend}
- Trend Confidence: {trend_confidence}
- Historical Baseline: {baseline_score}
- Improvement Percentage: {improvement_percentage}%
- Consistency Score: {consistency_score}

**Score Timeline:**
{score_timeline}

**Treatment Response Indicators:**
{treatment_indicators}

**Recovery Indicators:**
{recovery_indicators}

**Current Risk Factors:**
{current_risk_factors}

**Prognostic Factors:**
- Positive Factors: {positive_factors}
- Negative Factors: {negative_factors}

**Statistical Features:**
- Mean Score: {score_mean}
- Standard Deviation: {score_std}
- Score Range: {score_range}
- Variability Coefficient: {variability_coefficient}

Based on this historical data, please generate a comprehensive progress assessment report and long-term treatment recommendations in english."""
            }
        }
    
    def _init_database_tables(self):
        """åˆå§‹åŒ–AIé¡¾é—®æŠ¥å‘Šæ•°æ®åº“è¡¨"""
        try:
            conn = self.db_manager._get_connection()
            cursor = conn.cursor()
            
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS ai_advisor_reports (
                    report_id TEXT PRIMARY KEY,
                    user_id TEXT NOT NULL,
                    report_type TEXT NOT NULL CHECK(report_type IN ('single_test', 'historical_analysis')),
                    analysis_id TEXT,
                    generated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    
                    -- AIç”Ÿæˆçš„å†…å®¹
                    executive_summary TEXT NOT NULL,
                    clinical_assessment TEXT NOT NULL,
                    risk_evaluation TEXT NOT NULL,
                    treatment_recommendations TEXT NOT NULL,
                    lifestyle_recommendations TEXT NOT NULL,
                    monitoring_plan TEXT NOT NULL,
                    emergency_protocols TEXT NOT NULL,
                    
                    -- å†å²åˆ†æç‰¹æœ‰å†…å®¹
                    progress_analysis TEXT,
                    trend_interpretation TEXT,
                    prognosis_assessment TEXT,
                    
                    -- å…ƒæ•°æ®
                    confidence_score REAL DEFAULT 0.0,
                    ai_model_version TEXT DEFAULT 'deepseek-chat',
                    processing_time REAL DEFAULT 0.0,
                    
                    -- åŸå§‹æ•°æ®
                    ai_input_data TEXT,
                    ai_response_raw TEXT,
                    
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    
                    FOREIGN KEY (user_id) REFERENCES users (user_id) ON DELETE CASCADE,
                    FOREIGN KEY (analysis_id) REFERENCES mdq_analysis_results (analysis_id) ON DELETE SET NULL
                )
            ''')
            
            # åˆ›å»ºç´¢å¼•
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_advisor_user_type ON ai_advisor_reports(user_id, report_type)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_advisor_generated_at ON ai_advisor_reports(generated_at)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_advisor_analysis_id ON ai_advisor_reports(analysis_id)')
            
            conn.commit()
            print("AIé¡¾é—®æŠ¥å‘Šæ•°æ®åº“è¡¨åˆå§‹åŒ–å®Œæˆ")
            
        except sqlite3.Error as e:
            print(f"AIé¡¾é—®æ•°æ®åº“è¡¨åˆå§‹åŒ–å¤±è´¥: {e}")
        finally:
            if conn:
                conn.close()
    
    def generate_single_test_report(self, analysis_id: str) -> AdvisorReport:
        """ç”Ÿæˆå•æ¬¡æµ‹è¯•åˆ†ææŠ¥å‘Š - ä¿®å¤ç‰ˆ"""
        start_time = time.time()
        
        try:
            # è·å–åˆ†ææ•°æ®
            analysis_detail = self.analyzer.get_analysis_detail(analysis_id)
            if not analysis_detail:
                raise ValueError(f"åˆ†æè®°å½• {analysis_id} ä¸å­˜åœ¨")
            
            ai_data = self.analyzer.get_ai_analysis_data(analysis_id)
            if not ai_data:
                # å¦‚æœæ²¡æœ‰AIæ•°æ®ï¼Œå°è¯•ä»analysis_detailæ„é€ 
                print(f"è­¦å‘Šï¼šæ²¡æœ‰æ‰¾åˆ°AIåˆ†ææ•°æ®ï¼Œå°è¯•ä»åˆ†æè¯¦æƒ…æ„é€ åŸºç¡€æ•°æ®")
                ai_data = {
                    'mdq_part1_score': analysis_detail.get('mdq_part1_score', 0),
                    'has_co_occurrence': analysis_detail.get('has_co_occurrence', False),
                    'functional_impact_level': analysis_detail.get('functional_impact_level', 'no_problems'),
                    'mdq_result': analysis_detail.get('mdq_result', 'negative'),
                    'severity_level': analysis_detail.get('severity_level', 'negative'),
                    'risk_percentage': analysis_detail.get('risk_percentage', 0),
                    'positive_symptoms': json.loads(analysis_detail.get('positive_symptoms', '[]')) if analysis_detail.get('positive_symptoms') else [],
                    'core_symptoms_count': analysis_detail.get('core_symptoms_count', 0)
                }
            
            user_id = analysis_detail['user_id']
            
            # å‡†å¤‡AIè¾“å…¥æ•°æ®
            ai_input = self._prepare_single_test_input(ai_data)
            print(f"AIè¾“å…¥æ•°æ®å‡†å¤‡å®Œæˆ: MDQåˆ†æ•°={ai_input['mdq_score']}, é£é™©={ai_input['risk_percentage']}%")
            
            # è°ƒç”¨DeepSeek API
            user_prompt = self.prompts['single_test']['user_template'].format(**ai_input)
            
            try:
                ai_response = self._call_deepseek_api(
                    self.prompts['single_test']['system'],
                    user_prompt
                )
                print(f"DeepSeek APIè°ƒç”¨æˆåŠŸï¼Œå“åº”é•¿åº¦: {len(ai_response)}")
            except Exception as api_error:
                print(f"DeepSeek APIè°ƒç”¨å¤±è´¥: {api_error}")
                # ç”Ÿæˆå¤‡ç”¨æŠ¥å‘Š
                ai_response = self._generate_fallback_report(ai_input)
            
            # è§£æAIå“åº”
            parsed_response = self._parse_single_test_response(ai_response)
            
            # è®¡ç®—å¤„ç†æ—¶é—´
            processing_time = time.time() - start_time
            
            # åˆ›å»ºæŠ¥å‘Šå¯¹è±¡
            report = AdvisorReport(
                report_id=str(uuid.uuid4()),
                user_id=user_id,
                report_type='single_test',
                analysis_id=analysis_id,
                generated_at=datetime.now(),
                
                executive_summary=parsed_response['executive_summary'],
                clinical_assessment=parsed_response['clinical_assessment'],
                risk_evaluation=parsed_response['risk_evaluation'],
                treatment_recommendations=parsed_response['treatment_recommendations'],
                lifestyle_recommendations=parsed_response['lifestyle_recommendations'],
                monitoring_plan=parsed_response['monitoring_plan'],
                emergency_protocols=parsed_response['emergency_protocols'],
                
                confidence_score=parsed_response.get('confidence_score', 0.8),
                processing_time=processing_time
            )
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            self._save_report(report, ai_input, ai_response)
            
            return report
            
        except Exception as e:
            print(f"ç”Ÿæˆå•æ¬¡æµ‹è¯•æŠ¥å‘Šå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise e
    def _generate_fallback_report(self, ai_input: Dict) -> str:
        """Generate fallback report (when API call fails)"""
        mdq_score = ai_input.get('mdq_score', 0)
        risk_percentage = ai_input.get('risk_percentage', 0)

        if mdq_score >= 7:
            severity = "requires attention"
            recommendations = [
                "Consult with a mental health professional as soon as possible",
                "Monitor mood and behavioral changes closely",
                "Maintain regular sleep schedule"
            ]
            lifestyle = [
                "Avoid excessive stress and overstimulation",
                "Engage in moderate exercise",
                "Seek support from family and friends"
            ]
        else:
            severity = "relatively stable"
            recommendations = [
                "Continue monitoring mental health status",
                "Seek medical attention if symptoms change"
            ]
            lifestyle = [
                "Maintain healthy lifestyle habits",
                "Schedule regular mental health assessments"
            ]

        return f"""
    [EXECUTIVE SUMMARY]: Based on MDQ assessment results ({mdq_score}/13 points), the patient's current status is {severity}. Continued monitoring and professional evaluation are recommended.

    [CLINICAL ASSESSMENT]: The MDQ questionnaire shows a patient score of {mdq_score} points, with a risk assessment of {risk_percentage}%. According to standard MDQ scoring criteria, {'further professional evaluation is recommended' if mdq_score >= 7 else 'no obvious abnormalities, but continued monitoring is needed'}.

    [RISK EVALUATION]: {'Moderate risk - professional medical evaluation needed' if mdq_score >= 7 else 'Low risk - regular follow-up recommended'}.

    [TREATMENT RECOMMENDATIONS]:
    {chr(10).join(f'- {rec}' for rec in recommendations)}

    [LIFESTYLE RECOMMENDATIONS]:
    {chr(10).join(f'- {rec}' for rec in lifestyle)}

    [MONITORING PLAN]: {'Monthly' if mdq_score >= 7 else 'Quarterly'} mental health assessments are recommended. Seek medical attention promptly if symptoms change.

    [EMERGENCY PROTOCOLS]: If severe mood swings, self-harm or suicidal thoughts, or severe functional impairment occur, please contact a medical professional immediately or call emergency services.

    *Note: This report uses fallback generation mode due to network issues. Detailed evaluation by a professional physician is recommended.*
    """
    def generate_historical_analysis_report(self, user_id: str) -> AdvisorReport:
        """ç”Ÿæˆå†å²è¶‹åŠ¿åˆ†ææŠ¥å‘Š"""
        start_time = time.time()
        
        # è·å–ç”¨æˆ·æœ€æ–°åˆ†æ
        analysis_history = self.analyzer.get_analysis_history(user_id, limit=1)
        if not analysis_history:
            raise ValueError(f"ç”¨æˆ· {user_id} æ²¡æœ‰åˆ†æè®°å½•")
        
        latest_analysis_id = analysis_history[0]['analysis_id']
        ai_data = self.analyzer.get_ai_analysis_data(latest_analysis_id)
        
        if not ai_data:
            raise ValueError(f"ç”¨æˆ· {user_id} çš„AIæ•°æ®ä¸å®Œæ•´")
        
        # å‡†å¤‡AIè¾“å…¥æ•°æ®
        ai_input = self._prepare_historical_input(ai_data)
        
        # è°ƒç”¨DeepSeek API
        user_prompt = self.prompts['historical']['user_template'].format(**ai_input)
        ai_response = self._call_deepseek_api(
            self.prompts['historical']['system'],
            user_prompt
        )
        
        # è§£æAIå“åº”
        parsed_response = self._parse_historical_response(ai_response)
        
        # è®¡ç®—å¤„ç†æ—¶é—´
        processing_time = time.time() - start_time
        
        # åˆ›å»ºæŠ¥å‘Šå¯¹è±¡
        report = AdvisorReport(
            report_id=str(uuid.uuid4()),
            user_id=user_id,
            report_type='historical_analysis',
            analysis_id=latest_analysis_id,
            generated_at=datetime.now(),
            
            executive_summary=parsed_response['executive_summary'],
            clinical_assessment=parsed_response.get('clinical_assessment', ''),
            risk_evaluation=parsed_response.get('risk_evaluation', ''),
            treatment_recommendations=parsed_response.get('treatment_recommendations', ''),
            lifestyle_recommendations=parsed_response.get('lifestyle_recommendations', ''),
            monitoring_plan=parsed_response.get('monitoring_plan', ''),
            emergency_protocols=parsed_response.get('emergency_protocols', ''),
            
            progress_analysis=parsed_response['progress_analysis'],
            trend_interpretation=parsed_response['trend_interpretation'],
            prognosis_assessment=parsed_response['prognosis_assessment'],
            
            confidence_score=parsed_response.get('confidence_score', 0.8),
            processing_time=processing_time
        )
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        self._save_report(report, ai_input, ai_response)
        
        return report
    
    def _prepare_single_test_input(self, ai_data: Dict) -> Dict:
        """å‡†å¤‡å•æ¬¡æµ‹è¯•çš„AIè¾“å…¥æ•°æ® - ä¿®å¤ç‰ˆ"""
        try:
            # ä»ä¸åŒçš„æ•°æ®ç»“æ„ä¸­æå–ä¿¡æ¯
            demographics = ai_data.get('patient_demographics', {})
            mdq_standard = ai_data.get('mdq_standard_results', {})
            symptom_patterns = ai_data.get('symptom_patterns', {})
            clinical_context = ai_data.get('clinical_context', {})
            
            # å…¼å®¹æ—§æ•°æ®æ ¼å¼
            if not mdq_standard and 'mdq_part1_score' in ai_data:
                mdq_standard = {
                    'part1_score': ai_data.get('mdq_part1_score', 0),
                    'has_co_occurrence': ai_data.get('has_co_occurrence', False),
                    'functional_impact_level': ai_data.get('functional_impact_level', 'no_problems'),
                    'mdq_result': ai_data.get('mdq_result', 'negative'),
                    'severity_level': ai_data.get('severity_level', 'negative'),
                    'risk_percentage': ai_data.get('risk_percentage', 0)
                }
            
            if not symptom_patterns and 'positive_symptoms' in ai_data:
                symptom_patterns = {
                    'positive_symptoms_list': ai_data.get('positive_symptoms', []),
                    'core_symptoms_count': ai_data.get('core_symptoms_count', 0),
                    'symptom_profile': ai_data.get('symptom_profile', {})
                }
            
            # å®‰å…¨è·å–åŸºæœ¬ä¿¡æ¯
            age = demographics.get('age', ai_data.get('age', 'æœªçŸ¥'))
            gender = demographics.get('gender', ai_data.get('gender', 'æœªçŸ¥'))
            total_assessments = demographics.get('total_assessments', ai_data.get('total_assessments', 1))
            assessment_span = demographics.get('assessment_span_days', ai_data.get('assessment_span_days', 0))
            
            # å®‰å…¨è·å–MDQç›¸å…³ä¿¡æ¯
            mdq_score = mdq_standard.get('part1_score', ai_data.get('mdq_part1_score', 0))
            risk_percentage = mdq_standard.get('risk_percentage', ai_data.get('risk_percentage', 0))
            severity_level = mdq_standard.get('severity_level', ai_data.get('severity_level', 'negative'))
            functional_impact = mdq_standard.get('functional_impact_level', ai_data.get('functional_impact_level', 'no_problems'))
            
            # å¤„ç†ç—‡çŠ¶ä¿¡æ¯
            positive_symptoms = symptom_patterns.get('positive_symptoms_list', ai_data.get('positive_symptoms', []))
            core_symptoms_count = symptom_patterns.get('core_symptoms_count', ai_data.get('core_symptoms_count', 0))
            
            # æ ¼å¼åŒ–ç—‡çŠ¶åˆ†å¸ƒï¼ˆç®€åŒ–ç‰ˆï¼‰
            symptom_categories = symptom_patterns.get('symptom_categories', {})
            if not symptom_categories and 'symptom_profile' in ai_data:
                # ä»symptom_profileç”Ÿæˆç®€åŒ–çš„åˆ†ç±»
                profile = ai_data.get('symptom_profile', {})
                mood_symptoms = sum(1 for q in ['q1', 'q2'] if profile.get(q, False))
                cognitive_symptoms = sum(1 for q in ['q5', 'q6'] if profile.get(q, False))
                behavioral_symptoms = sum(1 for q in ['q7', 'q8', 'q9'] if profile.get(q, False))
                
                symptom_categories = {
                    'mood_elevation': {'positive_count': mood_symptoms, 'total_count': 2},
                    'cognitive_symptoms': {'positive_count': cognitive_symptoms, 'total_count': 2},
                    'behavioral_activation': {'positive_count': behavioral_symptoms, 'total_count': 3}
                }
            
            symptom_text = ""
            for category, data in symptom_categories.items():
                if isinstance(data, dict) and 'positive_count' in data:
                    symptom_text += f"- {category.replace('_', ' ').title()}: {data['positive_count']}/{data['total_count']}\n"

            # Format positive symptoms
            symptoms_text = "\n".join([f"- {symptom}" for symptom in positive_symptoms[:5]])  # Limit to first 5
            if not symptoms_text:
                symptoms_text = "No significant positive symptoms"
            
            # è·å–ä¸´åºŠä¸Šä¸‹æ–‡
            emergency_indicators = clinical_context.get('emergency_indicators', [])
            monitoring_priorities = clinical_context.get('monitoring_priorities', [])
            intervention_targets = clinical_context.get('intervention_targets', [])
            
            return {
                'age': str(age),
                'gender': str(gender),
                'total_assessments': int(total_assessments),
                'assessment_span_days': int(assessment_span),
                'mdq_score': int(mdq_score),
                'weighted_score': float(mdq_score),  # Simplified: use MDQ score
                'severity_level': str(severity_level).replace('_', ' ').title(),
                'risk_percentage': float(risk_percentage),
                'functional_impairment': str(functional_impact).replace('_', ' ').title(),
                'symptom_distribution': symptom_text if symptom_text else "No detailed symptom distribution data available",
                'bipolar_risk_profile': f"MDQ Positive: {'Yes' if mdq_score >= 7 else 'No'}\nSymptom Co-occurrence: {'Yes' if mdq_standard.get('has_co_occurrence', False) else 'No'}",
                'positive_symptoms': symptoms_text,
                'emergency_indicators': ', '.join(emergency_indicators) if emergency_indicators else 'None',
                'monitoring_priorities': ', '.join(monitoring_priorities) if monitoring_priorities else 'Routine monitoring',
                'intervention_targets': ', '.join(intervention_targets) if intervention_targets else 'No specific intervention targets'
            }
            
        except Exception as e:
            print(f"Failed to prepare AI input data: {e}")
            # Return basic data structure
            return {
                'age': 'Unknown',
                'gender': 'Unknown',
                'total_assessments': 1,
                'assessment_span_days': 0,
                'mdq_score': ai_data.get('mdq_part1_score', 0),
                'weighted_score': ai_data.get('mdq_part1_score', 0),
                'severity_level': 'Requires assessment',
                'risk_percentage': ai_data.get('risk_percentage', 0),
                'functional_impairment': 'Requires assessment',
                'symptom_distribution': 'Error occurred during data processing',
                'bipolar_risk_profile': 'Requires re-assessment',
                'positive_symptoms': 'Failed to retrieve data',
                'emergency_indicators': 'None',
                'monitoring_priorities': 'Professional assessment recommended',
                'intervention_targets': 'Further assessment required'
            }
    
    def _prepare_historical_input(self, ai_data: Dict) -> Dict:
        """å‡†å¤‡å†å²åˆ†æçš„AIè¾“å…¥æ•°æ®"""
        demographics = ai_data.get('patient_demographics', {})
        clinical_state = ai_data.get('current_clinical_state', {})
        trajectory = ai_data.get('historical_trajectory', {})
        treatment_response = ai_data.get('treatment_response', {})
        stats = ai_data.get('statistical_features', {})
        prognosis = ai_data.get('clinical_context', {}).get('prognosis_factors', {})
        
        # Format score timeline
        score_timeline = trajectory.get('score_timeline', [])
        timeline_text = "\n".join([
            f"- {point['date'][:10]}: {point['score']} points (Baseline deviation: {point['baseline_deviation']:+.1f})"
            for point in score_timeline[-10:]  # Last 10 records
        ])
        
        # æ ¼å¼åŒ–æ²»ç–—æŒ‡æ ‡
        treatment_indicators = treatment_response.get('treatment_indicators', {})
        treatment_text = "\n".join([f"- {k.replace('_', ' ').title()}: {v}" for k, v in treatment_indicators.items() if v != True])
        
        # æ ¼å¼åŒ–æ¢å¤æŒ‡æ ‡
        recovery_indicators = treatment_response.get('recovery_indicators', [])
        recovery_text = "\n".join([f"- {indicator}" for indicator in recovery_indicators])
        
        # æ ¼å¼åŒ–é£é™©å› ç´ 
        risk_factors = treatment_response.get('current_risk_factors', [])
        risk_text = "\n".join([f"- {factor}" for factor in risk_factors])
        
        return {
            'age': demographics.get('age', 'Unknown'),
            'gender': demographics.get('gender', 'Unknown'),
            'total_assessments': demographics.get('total_assessments', 0),
            'assessment_span_days': demographics.get('assessment_span_days', 0),
            'current_score': clinical_state.get('mdq_score', 0),
            'severity_level': clinical_state.get('severity_level', 'Unknown'),
            'risk_percentage': clinical_state.get('risk_percentage', 0),
            'improvement_trend': trajectory.get('improvement_trend', 'Unknown'),
            'trend_confidence': round(trajectory.get('trend_confidence', 0), 2),
            'baseline_score': round(trajectory.get('baseline_score', 0), 1),
            'improvement_percentage': round(treatment_response.get('improvement_percentage', 0), 1),
            'consistency_score': round(treatment_response.get('consistency_score', 0), 2),
            'score_timeline': timeline_text if timeline_text else 'Insufficient historical data available',
            'treatment_indicators': treatment_text if treatment_text else 'No treatment response data available',
            'recovery_indicators': recovery_text if recovery_text else 'No significant recovery indicators',
            'current_risk_factors': risk_text if risk_text else 'No significant risk factors',
            'positive_factors': ', '.join(prognosis.get('positive_factors', [])) if prognosis.get('positive_factors') else 'None',
            'negative_factors': ', '.join(prognosis.get('negative_factors', [])) if prognosis.get('negative_factors') else 'None',
            'score_mean': round(stats.get('score_mean', 0), 1),
            'score_std': round(stats.get('score_std', 0), 1),
            'score_range': stats.get('score_range', 0),
            'variability_coefficient': round(stats.get('variability_coefficient', 0), 2)
        }
    
    def _call_deepseek_api(self, system_prompt: str, user_prompt: str) -> str:
        """Call DeepSeek API - Enhanced error handling"""
        # If API unavailable, throw exception for fallback
        if not self.api_available or not self.client:
            raise Exception("DeepSeek API client not initialized or unavailable")

        try:
            # Add timeout and retry mechanism
            import time
            max_retries = 2  # Reduced retries for faster failure response

            for attempt in range(max_retries):
                try:
                    response = self.client.chat.completions.create(
                        model="deepseek-chat",
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        max_tokens=4000,
                        temperature=0.7,
                        stream=False,
                        timeout=30  # 30 second timeout
                    )

                    return response.choices[0].message.content

                except Exception as e:
                    print(f"DeepSeek API call failed (attempt {attempt + 1}/{max_retries}): {e}")
                    if attempt < max_retries - 1:
                        time.sleep(1)  # Fixed 1 second wait
                    else:
                        raise e

        except Exception as e:
            print(f"DeepSeek API call ultimately failed: {e}")
            raise Exception(f"DeepSeek API call failed: {str(e)}")
    
    def _parse_single_test_response(self, ai_response: str) -> Dict:
        """Parse single test AI response"""
        sections = {
            'executive_summary': '',
            'clinical_assessment': '',
            'risk_evaluation': '',
            'treatment_recommendations': [],
            'lifestyle_recommendations': [],
            'monitoring_plan': '',
            'emergency_protocols': '',
            'confidence_score': 0.8
        }

        # Split response by sections - support both English and Chinese formats
        section_patterns = {
            '[EXECUTIVE SUMMARY]': 'executive_summary',
            '[CLINICAL ASSESSMENT]': 'clinical_assessment',
            '[RISK EVALUATION]': 'risk_evaluation',
            '[TREATMENT RECOMMENDATIONS]': 'treatment_recommendations',
            '[LIFESTYLE RECOMMENDATIONS]': 'lifestyle_recommendations',
            '[MONITORING PLAN]': 'monitoring_plan',
            '[EMERGENCY PROTOCOLS]': 'emergency_protocols',
            # Fallback to Chinese patterns for compatibility
            'ã€æ‰§è¡Œæ‘˜è¦ã€‘': 'executive_summary',
            'ã€ä¸´åºŠè¯„ä¼°ã€‘': 'clinical_assessment',
            'ã€é£é™©è¯„ä¼°ã€‘': 'risk_evaluation',
            'ã€æ²»ç–—å»ºè®®ã€‘': 'treatment_recommendations',
            'ã€ç”Ÿæ´»æ–¹å¼å»ºè®®ã€‘': 'lifestyle_recommendations',
            'ã€ç›‘æµ‹è®¡åˆ’ã€‘': 'monitoring_plan',
            'ã€ç´§æ€¥é¢„æ¡ˆã€‘': 'emergency_protocols'
        }
        
        current_section = None
        lines = ai_response.split('\n')
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°çš„ç« èŠ‚
            section_found = False
            for pattern, section_name in section_patterns.items():
                if pattern in line:
                    current_section = section_name
                    section_found = True
                    # æå–ç« èŠ‚æ ‡é¢˜åçš„å†…å®¹
                    content = line.replace(pattern, '').strip('ï¼š: ')
                    if content:
                        if section_name in ['treatment_recommendations', 'lifestyle_recommendations']:
                            if content.startswith('-'):
                                sections[section_name].append(content[1:].strip())
                            else:
                                sections[section_name].append(content)
                        else:
                            sections[section_name] = content
                    break
            
            if not section_found and current_section:
                # ç»§ç»­å½“å‰ç« èŠ‚çš„å†…å®¹
                if current_section in ['treatment_recommendations', 'lifestyle_recommendations']:
                    if line.startswith('-'):
                        sections[current_section].append(line[1:].strip())
                    elif line.startswith(('â€¢', '*', '1.', '2.', '3.', '4.', '5.')):
                        clean_line = line.lstrip('â€¢*123456789. ')
                        sections[current_section].append(clean_line)
                    elif sections[current_section] and not any(x in line for x in ['ã€', 'ã€‘']):
                        # å¦‚æœä¸æ˜¯æ–°ç« èŠ‚ä¸”æœ‰å†…å®¹ï¼Œè¿½åŠ åˆ°æœ€åä¸€ä¸ªå»ºè®®
                        sections[current_section][-1] += ' ' + line
                else:
                    if sections[current_section]:
                        sections[current_section] += ' ' + line
                    else:
                        sections[current_section] = line
        
        # Ensure required fields are not empty
        if not sections['executive_summary']:
            sections['executive_summary'] = 'Patient requires further evaluation by a professional physician'
        if not sections['clinical_assessment']:
            sections['clinical_assessment'] = 'Comprehensive clinical assessment is recommended'
        if not sections['risk_evaluation']:
            sections['risk_evaluation'] = 'Risk assessment requires professional medical judgment'
        if not sections['treatment_recommendations']:
            sections['treatment_recommendations'] = ['Consult with a psychiatrist to develop a personalized treatment plan']
        if not sections['lifestyle_recommendations']:
            sections['lifestyle_recommendations'] = ['Maintain regular sleep schedule and healthy lifestyle habits']
        if not sections['monitoring_plan']:
            sections['monitoring_plan'] = 'Regular follow-up and symptom monitoring recommended'
        if not sections['emergency_protocols']:
            sections['emergency_protocols'] = 'In case of emergency, contact a physician immediately or call emergency services'

        return sections
    
    def _parse_historical_response(self, ai_response: str) -> Dict:
        """Parse historical analysis AI response"""
        # Define 5 section parsing patterns - support both English and Chinese
        historical_patterns = {
            '[EXECUTIVE SUMMARY]': 'executive_summary',
            '[PROGRESS ANALYSIS]': 'progress_analysis',
            '[TREND INTERPRETATION]': 'trend_interpretation',
            '[TREATMENT RECOMMENDATIONS]': 'treatment_recommendations',
            '[PROGNOSIS ASSESSMENT]': 'prognosis_assessment',
            # Fallback to Chinese patterns for compatibility
            'ã€æ‰§è¡Œæ‘˜è¦ã€‘': 'executive_summary',
            'ã€è¿›å±•åˆ†æã€‘': 'progress_analysis',
            'ã€è¶‹åŠ¿è§£è¯»ã€‘': 'trend_interpretation',
            'ã€æ²»ç–—å»ºè®®ã€‘': 'treatment_recommendations',
            'ã€é¢„åè¯„ä¼°ã€‘': 'prognosis_assessment'
        }

        # Initialize all fields
        sections = {
            'executive_summary': '',
            'progress_analysis': '',
            'trend_interpretation': '',
            'treatment_recommendations': '',
            'prognosis_assessment': ''
        }
        
        current_section = None
        lines = ai_response.split('\n')
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # æ£€æŸ¥å†å²åˆ†æç« èŠ‚
            for pattern, section_name in historical_patterns.items():
                if pattern in line:
                    current_section = section_name
                    content = line.replace(pattern, '').strip('ï¼š: ')
                    if content:
                        sections[section_name] = content
                    break
            else:
                # ç»§ç»­å½“å‰å†å²åˆ†æç« èŠ‚çš„å†…å®¹
                if current_section and current_section in historical_patterns.values():
                    if sections[current_section]:
                        sections[current_section] += ' ' + line
                    else:
                        sections[current_section] = line
        
        # Provide default values for empty historical analysis fields
        if not sections['executive_summary']:
            sections['executive_summary'] = 'Based on historical data analysis, overall treatment progress requires continuous monitoring and professional evaluation'
        if not sections['progress_analysis']:
            sections['progress_analysis'] = 'Based on available data, treatment progress requires continuous monitoring and professional evaluation'
        if not sections['trend_interpretation']:
            sections['trend_interpretation'] = 'Symptom trend changes require comprehensive assessment in conjunction with clinical presentation'
        if not sections['treatment_recommendations']:
            sections['treatment_recommendations'] = 'Continue current treatment plan with regular effectiveness assessments'
        if not sections['prognosis_assessment']:
            sections['prognosis_assessment'] = 'Prognosis assessment requires consideration of multiple factors. Regular professional evaluation is recommended'

        return sections
    
    def _save_report(self, report: AdvisorReport, ai_input: Dict, ai_response: str) -> bool:
        """ä¿å­˜æŠ¥å‘Šåˆ°æ•°æ®åº“"""
        try:
            conn = self.db_manager._get_connection()
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO ai_advisor_reports (
                    report_id, user_id, report_type, analysis_id, generated_at,
                    executive_summary, clinical_assessment, risk_evaluation,
                    treatment_recommendations, lifestyle_recommendations,
                    monitoring_plan, emergency_protocols,
                    progress_analysis, trend_interpretation, prognosis_assessment,
                    confidence_score, ai_model_version, processing_time,
                    ai_input_data, ai_response_raw
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                report.report_id,
                report.user_id,
                report.report_type,
                report.analysis_id,
                report.generated_at.isoformat(),
                report.executive_summary,
                getattr(report, 'clinical_assessment', ''),
                getattr(report, 'risk_evaluation', ''),
                json.dumps(getattr(report, 'treatment_recommendations', ''), ensure_ascii=False),
                json.dumps(getattr(report, 'lifestyle_recommendations', ''), ensure_ascii=False),
                getattr(report, 'monitoring_plan', ''),
                getattr(report, 'emergency_protocols', ''),
                report.progress_analysis,
                report.trend_interpretation,
                report.prognosis_assessment,
                report.confidence_score,
                report.ai_model_version,
                report.processing_time,
                json.dumps(ai_input, ensure_ascii=False),
                ai_response
            ))
            
            conn.commit()
            print(f"AIé¡¾é—®æŠ¥å‘Šå·²ä¿å­˜: {report.report_id}")
            return True
            
        except sqlite3.Error as e:
            print(f"ä¿å­˜AIé¡¾é—®æŠ¥å‘Šå¤±è´¥: {e}")
            return False
        finally:
            if conn:
                conn.close()
    
    def get_report(self, report_id: str) -> Optional[Dict]:
        """è·å–æŠ¥å‘Šè¯¦æƒ…"""
        try:
            conn = self.db_manager._get_connection()
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT * FROM ai_advisor_reports WHERE report_id = ?
            ''', (report_id,))
            
            result = cursor.fetchone()
            
            if result:
                columns = [description[0] for description in cursor.description]
                report_data = dict(zip(columns, result))
                
                # è§£æJSONå­—æ®µ
                json_fields = ['treatment_recommendations', 'lifestyle_recommendations', 
                             'ai_input_data']
                
                for field in json_fields:
                    if report_data[field]:
                        try:
                            report_data[field] = json.loads(report_data[field])
                        except json.JSONDecodeError:
                            pass
                
                return report_data
            
            return None
            
        except sqlite3.Error as e:
            print(f"è·å–AIæŠ¥å‘Šå¤±è´¥: {e}")
            return None
        finally:
            if conn:
                conn.close()
    
    def get_user_reports(self, user_id: str, report_type: Optional[str] = None, limit: int = 10) -> List[Dict]:
        """è·å–ç”¨æˆ·çš„æŠ¥å‘Šå†å²"""
        try:
            conn = self.db_manager._get_connection()
            cursor = conn.cursor()
            
            query = '''
                SELECT report_id, report_type, generated_at, confidence_score, processing_time
                FROM ai_advisor_reports
                WHERE user_id = ?
            '''
            params = [user_id]
            
            if report_type:
                query += ' AND report_type = ?'
                params.append(report_type)
            
            query += ' ORDER BY generated_at DESC LIMIT ?'
            params.append(limit)
            
            cursor.execute(query, params)
            results = cursor.fetchall()
            
            return [{
                'report_id': row[0],
                'report_type': row[1],
                'generated_at': row[2],
                'confidence_score': row[3],
                'processing_time': row[4]
            } for row in results]
            
        except sqlite3.Error as e:
            print(f"è·å–ç”¨æˆ·æŠ¥å‘Šå†å²å¤±è´¥: {e}")
            return []
        finally:
            if conn:
                conn.close()

# ä¾¿æ·åŠŸèƒ½å‡½æ•°
def generate_quick_report(user_id: str, report_type: str = 'both') -> Dict:
    """å¿«é€Ÿç”ŸæˆæŠ¥å‘Šçš„ä¾¿æ·å‡½æ•°"""
    db_manager = DatabaseManager()
    analyzer = MDQAnalyzer(db_manager)
    advisor = DeepSeekAdvisor(db_manager, analyzer)
    
    results = {}
    
    try:
        if report_type in ['single', 'both']:
            # è·å–æœ€æ–°åˆ†æID
            analysis_history = analyzer.get_analysis_history(user_id, limit=1)
            if analysis_history:
                analysis_id = analysis_history[0]['analysis_id']
                single_report = advisor.generate_single_test_report(analysis_id)
                results['single_test_report'] = {
                    'report_id': single_report.report_id,
                    'executive_summary': single_report.executive_summary,
                    'treatment_recommendations': single_report.treatment_recommendations,
                    'emergency_protocols': single_report.emergency_protocols
                }
        
        if report_type in ['historical', 'both']:
            historical_report = advisor.generate_historical_analysis_report(user_id)
            results['historical_report'] = {
                'report_id': historical_report.report_id,
                'progress_analysis': historical_report.progress_analysis,
                'trend_interpretation': historical_report.trend_interpretation,
                'prognosis_assessment': historical_report.prognosis_assessment
            }
        
        return {'success': True, 'reports': results}
        
    except Exception as e:
        return {'success': False, 'error': str(e)}

def batch_generate_reports(report_type: str = 'both') -> Dict:
    """æ‰¹é‡ä¸ºæ‰€æœ‰ç”¨æˆ·ç”ŸæˆæŠ¥å‘Š"""
    db_manager = DatabaseManager()
    analyzer = MDQAnalyzer(db_manager)
    advisor = DeepSeekAdvisor(db_manager, analyzer)
    
    try:
        conn = db_manager._get_connection()
        cursor = conn.cursor()
        
        # è·å–æ‰€æœ‰æœ‰åˆ†æè®°å½•çš„ç”¨æˆ·
        cursor.execute('''
            SELECT DISTINCT user_id FROM mdq_analysis_results
        ''')
        
        user_ids = [row[0] for row in cursor.fetchall()]
        
        results = {
            'total_users': len(user_ids),
            'successful_reports': 0,
            'failed_reports': 0,
            'reports': {}
        }
        
        for user_id in user_ids:
            try:
                user_results = generate_quick_report(user_id, report_type)
                if user_results['success']:
                    results['successful_reports'] += 1
                    results['reports'][user_id] = user_results['reports']
                else:
                    results['failed_reports'] += 1
                    print(f"ç”¨æˆ· {user_id[:8]} æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {user_results['error']}")
                    
            except Exception as e:
                results['failed_reports'] += 1
                print(f"ç”¨æˆ· {user_id[:8]} æŠ¥å‘Šç”Ÿæˆå‡ºé”™: {e}")
        
        return results
        
    except Exception as e:
        return {'success': False, 'error': str(e)}
        
    finally:
        if conn:
            conn.close()

# æŠ¥å‘Šæ ¼å¼åŒ–å’Œå¯¼å‡ºåŠŸèƒ½
def format_report_for_display(report_data: Dict) -> str:
    """æ ¼å¼åŒ–æŠ¥å‘Šç”¨äºæ˜¾ç¤º"""
    if not report_data:
        return "æŠ¥å‘Šä¸å­˜åœ¨"
    
    report_type_names = {
        'single_test': 'å•æ¬¡æµ‹è¯•åˆ†ææŠ¥å‘Š',
        'historical_analysis': 'å†å²è¶‹åŠ¿åˆ†ææŠ¥å‘Š'
    }
    
    formatted_text = f"""
# {report_type_names.get(report_data['report_type'], 'åˆ†ææŠ¥å‘Š')}

**æŠ¥å‘ŠID:** {report_data['report_id']}
**ç”Ÿæˆæ—¶é—´:** {report_data['generated_at'][:19]}
**AIæ¨¡å‹:** {report_data['ai_model_version']}
**ç½®ä¿¡åº¦:** {report_data['confidence_score']:.2f}
**å¤„ç†æ—¶é—´:** {report_data['processing_time']:.2f}ç§’

---

## ğŸ“‹ æ‰§è¡Œæ‘˜è¦
{report_data['executive_summary']}

## ğŸ¥ ä¸´åºŠè¯„ä¼°
{report_data['clinical_assessment']}

## âš ï¸ é£é™©è¯„ä¼°
{report_data['risk_evaluation']}

## ğŸ’Š æ²»ç–—å»ºè®®
"""
    
    # å¤„ç†æ²»ç–—å»ºè®®
    treatment_recs = report_data['treatment_recommendations']
    if isinstance(treatment_recs, list):
        for i, rec in enumerate(treatment_recs, 1):
            formatted_text += f"{i}. {rec}\n"
    else:
        formatted_text += f"{treatment_recs}\n"
    
    formatted_text += "\n## ğŸ’¡ ç”Ÿæ´»æ–¹å¼å»ºè®®\n"
    
    # å¤„ç†ç”Ÿæ´»æ–¹å¼å»ºè®®
    lifestyle_recs = report_data['lifestyle_recommendations']
    if isinstance(lifestyle_recs, list):
        for i, rec in enumerate(lifestyle_recs, 1):
            formatted_text += f"{i}. {rec}\n"
    else:
        formatted_text += f"{lifestyle_recs}\n"
    
    formatted_text += f"""
## ğŸ“… ç›‘æµ‹è®¡åˆ’
{report_data['monitoring_plan']}

## ğŸš¨ ç´§æ€¥é¢„æ¡ˆ
{report_data['emergency_protocols']}
"""
    
    # å¦‚æœæ˜¯å†å²åˆ†ææŠ¥å‘Šï¼Œæ·»åŠ é¢å¤–å†…å®¹
    if report_data['report_type'] == 'historical_analysis':
        formatted_text += f"""
---

## ğŸ“ˆ è¿›å±•åˆ†æ
{report_data['progress_analysis']}

## ğŸ“Š è¶‹åŠ¿è§£è¯»
{report_data['trend_interpretation']}

## ğŸ”® é¢„åè¯„ä¼°
{report_data['prognosis_assessment']}
"""
    
    return formatted_text

def export_report_to_file(report_id: str, filename: Optional[str] = None) -> str:
    """å¯¼å‡ºæŠ¥å‘Šåˆ°æ–‡ä»¶"""
    db_manager = DatabaseManager()
    analyzer = MDQAnalyzer(db_manager)
    advisor = DeepSeekAdvisor(db_manager, analyzer)
    
    report = advisor.get_report(report_id)
    if not report:
        return "æŠ¥å‘Šä¸å­˜åœ¨"
    
    if filename is None:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"mdq_report_{report_id[:8]}_{timestamp}.txt"
    
    formatted_text = format_report_for_display(report)
    
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(formatted_text)
        return f"æŠ¥å‘Šå·²å¯¼å‡ºåˆ°: {filename}"
    except Exception as e:
        return f"å¯¼å‡ºå¤±è´¥: {e}"

# æµ‹è¯•å‡½æ•°
def test_deepseek_advisor():
    """æµ‹è¯•DeepSeek AIé¡¾é—®åŠŸèƒ½"""
    print("=== DeepSeek AI é¡¾é—®ç³»ç»Ÿæµ‹è¯• ===")
    
    # æ£€æŸ¥APIå¯†é’¥è®¾ç½®
    if DEEPSEEK_API_KEY == "your_deepseek_api_key_here":
        print("âŒ è¯·å…ˆåœ¨æ–‡ä»¶é¡¶éƒ¨è®¾ç½®æœ‰æ•ˆçš„ DeepSeek API å¯†é’¥")
        print("è¯·ä¿®æ”¹æ–‡ä»¶é¡¶éƒ¨çš„ DEEPSEEK_API_KEY å˜é‡")
        print("è·å–APIå¯†é’¥: https://platform.deepseek.com/")
        return
    
    # åˆå§‹åŒ–ç»„ä»¶
    try:
        db_manager = DatabaseManager()
        analyzer = MDQAnalyzer(db_manager)
        advisor = DeepSeekAdvisor(db_manager, analyzer)
        print("âœ… AIé¡¾é—®ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # æŸ¥æ‰¾ç°æœ‰ç”¨æˆ·è¿›è¡Œæµ‹è¯•
    try:
        conn = db_manager._get_connection()
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT DISTINCT ar.user_id, ar.analysis_id, u.username
            FROM mdq_analysis_results ar
            JOIN users u ON ar.user_id = u.user_id
            ORDER BY ar.analysis_date DESC
            LIMIT 1
        ''')
        
        result = cursor.fetchone()
        
        if not result:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°åˆ†æç»“æœï¼Œè¯·å…ˆè¿è¡Œ analyse.py ç”Ÿæˆåˆ†ææ•°æ®")
            return
        
        user_id, analysis_id, username = result
        print(f"æµ‹è¯•ç”¨æˆ·: {username} (ID: {user_id[:8]}...)")
        print(f"åˆ†æID: {analysis_id[:8]}...")
        
        # æµ‹è¯•1: ç”Ÿæˆå•æ¬¡åˆ†ææŠ¥å‘Š
        print(f"\n=== æµ‹è¯•1: ç”Ÿæˆå•æ¬¡æµ‹è¯•åˆ†ææŠ¥å‘Š ===")
        try:
            print("æ­£åœ¨è°ƒç”¨DeepSeek APIç”ŸæˆæŠ¥å‘Š...")
            single_report = advisor.generate_single_test_report(analysis_id)
            
            print("âœ… å•æ¬¡åˆ†ææŠ¥å‘Šç”ŸæˆæˆåŠŸ!")
            print(f"æŠ¥å‘ŠID: {single_report.report_id}")
            print(f"å¤„ç†æ—¶é—´: {single_report.processing_time:.2f}ç§’")
            print(f"ç½®ä¿¡åº¦: {single_report.confidence_score:.2f}")
            
            print(f"\nğŸ“‹ æ‰§è¡Œæ‘˜è¦:")
            print(f"{single_report.executive_summary}")
            
            print(f"\nğŸ¥ æ²»ç–—å»ºè®®:")
            for i, rec in enumerate(single_report.treatment_recommendations[:3], 1):
                print(f"  {i}. {rec}")
            
            print(f"\nğŸ’¡ ç”Ÿæ´»æ–¹å¼å»ºè®®:")
            for i, rec in enumerate(single_report.lifestyle_recommendations[:3], 1):
                print(f"  {i}. {rec}")
                
        except Exception as e:
            print(f"âŒ å•æ¬¡åˆ†ææŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            print("è¯·æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®ï¼Œä»¥åŠç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        
        # æµ‹è¯•2: ç”Ÿæˆå†å²åˆ†ææŠ¥å‘Š
        print(f"\n=== æµ‹è¯•2: ç”Ÿæˆå†å²è¶‹åŠ¿åˆ†ææŠ¥å‘Š ===")
        try:
            print("æ­£åœ¨è°ƒç”¨DeepSeek APIç”Ÿæˆå†å²åˆ†ææŠ¥å‘Š...")
            historical_report = advisor.generate_historical_analysis_report(user_id)
            
            print("âœ… å†å²åˆ†ææŠ¥å‘Šç”ŸæˆæˆåŠŸ!")
            print(f"æŠ¥å‘ŠID: {historical_report.report_id}")
            print(f"å¤„ç†æ—¶é—´: {historical_report.processing_time:.2f}ç§’")
            print(f"ç½®ä¿¡åº¦: {historical_report.confidence_score:.2f}")
            
            print(f"\nğŸ“ˆ è¿›å±•åˆ†æ:")
            print(f"{historical_report.progress_analysis[:200]}...")
            
            print(f"\nğŸ“Š è¶‹åŠ¿è§£è¯»:")
            print(f"{historical_report.trend_interpretation[:200]}...")
            
            print(f"\nğŸ”® é¢„åè¯„ä¼°:")
            print(f"{historical_report.prognosis_assessment[:200]}...")
            
        except Exception as e:
            print(f"âŒ å†å²åˆ†ææŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
        
        # æµ‹è¯•3: æŠ¥å‘Šè·å–åŠŸèƒ½
        print(f"\n=== æµ‹è¯•3: æŠ¥å‘Šè·å–åŠŸèƒ½ ===")
        user_reports = advisor.get_user_reports(user_id)
        print(f"ç”¨æˆ·æŠ¥å‘Šå†å²: {len(user_reports)} ä¸ª")
        
        for report in user_reports:
            print(f"  - {report['report_type']}: {report['generated_at'][:19]} "
                  f"(ç½®ä¿¡åº¦: {report['confidence_score']:.2f}, "
                  f"å¤„ç†æ—¶é—´: {report['processing_time']:.2f}s)")
        
        # æµ‹è¯•4: æŠ¥å‘Šæ ¼å¼åŒ–
        if user_reports:
            print(f"\n=== æµ‹è¯•4: æŠ¥å‘Šæ ¼å¼åŒ– ===")
            latest_report_id = user_reports[0]['report_id']
            report_detail = advisor.get_report(latest_report_id)
            
            if report_detail:
                formatted_report = format_report_for_display(report_detail)
                print("âœ… æŠ¥å‘Šæ ¼å¼åŒ–æˆåŠŸ")
                print(f"æ ¼å¼åŒ–æŠ¥å‘Šé•¿åº¦: {len(formatted_report)} å­—ç¬¦")
                
                # æ˜¾ç¤ºæŠ¥å‘Šæ‘˜è¦
                lines = formatted_report.split('\n')
                for line in lines[:15]:  # æ˜¾ç¤ºå‰15è¡Œ
                    print(line)
                print("...")
            else:
                print("âŒ è·å–æŠ¥å‘Šè¯¦æƒ…å¤±è´¥")
        
        print(f"\nğŸ‰ AIé¡¾é—®ç³»ç»Ÿæµ‹è¯•å®Œæˆ!")
        print("âœ… å•æ¬¡æµ‹è¯•æŠ¥å‘Šç”ŸæˆåŠŸèƒ½æ­£å¸¸")
        print("âœ… å†å²åˆ†ææŠ¥å‘Šç”ŸæˆåŠŸèƒ½æ­£å¸¸") 
        print("âœ… æ•°æ®åº“ä¿å­˜åŠŸèƒ½æ­£å¸¸")
        print("âœ… æŠ¥å‘Šè·å–åŠŸèƒ½æ­£å¸¸")
        print("âœ… æŠ¥å‘Šæ ¼å¼åŒ–åŠŸèƒ½æ­£å¸¸")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        if conn:
            conn.close()

# å¿«é€Ÿæ¼”ç¤ºå‡½æ•°
def demo_advisor_workflow(user_id: str = None):
    """æ¼”ç¤ºAIé¡¾é—®å®Œæ•´å·¥ä½œæµç¨‹"""
    print("=== AIé¡¾é—®å·¥ä½œæµç¨‹æ¼”ç¤º ===")
    
    if DEEPSEEK_API_KEY == "your_deepseek_api_key_here":
        print("âŒ è¯·å…ˆè®¾ç½®APIå¯†é’¥")
        return
    
    db_manager = DatabaseManager()
    analyzer = MDQAnalyzer(db_manager)
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šç”¨æˆ·ï¼Œè‡ªåŠ¨é€‰æ‹©
    if not user_id:
        try:
            conn = db_manager._get_connection()
            cursor = conn.cursor()
            cursor.execute('SELECT DISTINCT user_id FROM mdq_analysis_results LIMIT 1')
            result = cursor.fetchone()
            if result:
                user_id = result[0]
            else:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°ç”¨æˆ·æ•°æ®")
                return
        finally:
            if conn:
                conn.close()
    
    try:
        advisor = DeepSeekAdvisor(db_manager, analyzer)
        
        print(f"ç”¨æˆ·ID: {user_id[:8]}...")
        
        # ç”Ÿæˆä¸¤ç§ç±»å‹çš„æŠ¥å‘Š
        print("\n1. ç”Ÿæˆå•æ¬¡æµ‹è¯•æŠ¥å‘Š...")
        single_result = generate_quick_report(user_id, 'single')
        
        print("2. ç”Ÿæˆå†å²åˆ†ææŠ¥å‘Š...")
        historical_result = generate_quick_report(user_id, 'historical')
        
        # æ˜¾ç¤ºç»“æœæ‘˜è¦
        if single_result['success']:
            single_id = single_result['reports']['single_test_report']['report_id']
            print(f"âœ… å•æ¬¡æŠ¥å‘Šç”Ÿæˆ: {single_id[:8]}...")
        
        if historical_result['success']:
            historical_id = historical_result['reports']['historical_report']['report_id'] 
            print(f"âœ… å†å²æŠ¥å‘Šç”Ÿæˆ: {historical_id[:8]}...")
        
        print("\nğŸ“Š å·¥ä½œæµç¨‹æ¼”ç¤ºå®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")

if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    test_deepseek_advisor()
    
    # å¯ä»¥å–æ¶ˆæ³¨é‡Šä¸‹é¢çš„è¡Œæ¥è¿è¡Œå…¶ä»–åŠŸèƒ½
    # demo_advisor_workflow()  # æ¼”ç¤ºå®Œæ•´å·¥ä½œæµç¨‹
    # batch_generate_reports('both')  # æ‰¹é‡ç”Ÿæˆæ‰€æœ‰ç”¨æˆ·æŠ¥å‘Š